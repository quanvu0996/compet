{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kalapa_4student_net2_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/quanvu0996/compet/blob/master/kalapa_4student_net2_tensorflow.ipynb",
      "authorship_tag": "ABX9TyM7icKxhHqtQqLjE6SORPWu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quanvu0996/compet/blob/master/kalapa_4student_net2_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OD0B2zVuWpZ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, DenseFeatures, Dropout, BatchNormalization\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow import feature_column as fc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xw8EKyqXF34",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e13d0859-1d1a-456d-8843-4c31c692496f"
      },
      "source": [
        "print(pd.__version__)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.5\n",
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zy1CWgz8Xo2a",
        "colab_type": "text"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-kw2uF8XI8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submision_path = '/content/drive/My Drive/Data/colabs_data/kalapa_4students/simple_submission.csv'\n",
        "train_path = '/content/drive/My Drive/Data/colabs_data/kalapa_4students/train.csv'\n",
        "test_path = '/content/drive/My Drive/Data/colabs_data/kalapa_4students/test.csv'"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6MXUjGuXLQa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "ea233c07-f09a-4221-fc28-39f2754e1595"
      },
      "source": [
        "def load_data(train_path, test_path, label_col = 'label'):\n",
        "    train_set = pd.read_csv(train_path)\n",
        "    test_set = pd.read_csv(test_path)\n",
        "    return train_set, test_set\n",
        "\n",
        "train_set, test_set = load_data( train_path, test_path )\n",
        "cols = train_set.columns"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (35,43) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (34,42) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pPllECZx4X1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "1f10c9a3-1c69-493d-8b61-5b956d2338ef"
      },
      "source": [
        "train_set.info()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 53030 entries, 0 to 53029\n",
            "Columns: 195 entries, id to Field_82\n",
            "dtypes: float64(133), int64(3), object(59)\n",
            "memory usage: 78.9+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9GQa7jQXv8g",
        "colab_type": "text"
      },
      "source": [
        "### Data trasforming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckJE8Rza3Lco",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_set[cols_categorical].head()\n",
        "# train_set.Field_61.unique()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPNgmPkZ9JgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(train_set.Field_45.unique())\n",
        "# cols_id"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKyv3i9N_NRe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# len(train_set.homeTownCity.unique())"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaeOcozU419_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_set.C_endDate.unique()\n",
        "# train_set.homeTownCity.hist()\n",
        "# print(cols_docs)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YBy1t6IdBRfM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "669dba83-e757-4c97-e2c1-28ed9b4d8d82"
      },
      "source": [
        "train_set[cols_date].head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Field_1</th>\n",
              "      <th>Field_2</th>\n",
              "      <th>Field_5</th>\n",
              "      <th>Field_6</th>\n",
              "      <th>Field_7</th>\n",
              "      <th>Field_8</th>\n",
              "      <th>Field_9</th>\n",
              "      <th>Field_10</th>\n",
              "      <th>Field_11</th>\n",
              "      <th>Field_14</th>\n",
              "      <th>Field_15</th>\n",
              "      <th>Field_25</th>\n",
              "      <th>Field_32</th>\n",
              "      <th>Field_33</th>\n",
              "      <th>Field_34</th>\n",
              "      <th>Field_35</th>\n",
              "      <th>Field_40</th>\n",
              "      <th>Field_43</th>\n",
              "      <th>Field_44</th>\n",
              "      <th>F_startDate</th>\n",
              "      <th>F_endDate</th>\n",
              "      <th>E_startDate</th>\n",
              "      <th>E_endDate</th>\n",
              "      <th>C_startDate</th>\n",
              "      <th>C_endDate</th>\n",
              "      <th>G_startDate</th>\n",
              "      <th>G_endDate</th>\n",
              "      <th>A_startDate</th>\n",
              "      <th>A_endDate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2019-07-24T03:39:02.854Z</td>\n",
              "      <td>2019-07-31T20:10:02Z</td>\n",
              "      <td>2018-12-27</td>\n",
              "      <td>2018-12-27</td>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>2019-07-31</td>\n",
              "      <td>2018-12-27</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2019-07-31</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2018-12-27</td>\n",
              "      <td>2018-12-28</td>\n",
              "      <td>2022-09-01</td>\n",
              "      <td>20180107</td>\n",
              "      <td>2019-07-31</td>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>2017-01-03T16:06:41.157Z</td>\n",
              "      <td>2019-11-12T04:09:58.381Z</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019-06-11</td>\n",
              "      <td>2019-08-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019-07-17</td>\n",
              "      <td>2019-07-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-01-17T07:15:26.367Z</td>\n",
              "      <td>2019-01-17T07:17:45Z</td>\n",
              "      <td>2019-01-17</td>\n",
              "      <td>2019-01-17</td>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>2019-12-31</td>\n",
              "      <td>2019-01-17</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2019-01-17</td>\n",
              "      <td>2019-01-17</td>\n",
              "      <td>2019-01-17</td>\n",
              "      <td>2023-03-01</td>\n",
              "      <td>20190102</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>2019-01-07T08:29:01.623Z</td>\n",
              "      <td>2019-08-26T09:27:23.191Z</td>\n",
              "      <td>2019-08-18</td>\n",
              "      <td>2019-08-18</td>\n",
              "      <td>2019-08-18</td>\n",
              "      <td>2019-09-11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2019-09-19</td>\n",
              "      <td>2019-11-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    Field_1               Field_2  ... A_startDate   A_endDate\n",
              "0  2019-07-24T03:39:02.854Z  2019-07-31T20:10:02Z  ...  2019-06-11  2019-08-17\n",
              "1                       NaN                   NaN  ...  2019-07-17  2019-07-17\n",
              "2  2019-01-17T07:15:26.367Z  2019-01-17T07:17:45Z  ...  2019-09-19  2019-11-05\n",
              "3                       NaN                   NaN  ...         NaN         NaN\n",
              "4                       NaN                   NaN  ...         NaN         NaN\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGfzWBUhX-6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Nhãn\n",
        "cols_label = ['label']\n",
        "# Đặc trưng binary\n",
        "cols_fts_binary = [i for i in train_set.select_dtypes(include=['float64','int64']).columns \n",
        "                   if len(set(train_set[i].fillna(0)) - {0,1} ) == 0 and i not in cols_label]\n",
        "# định dang datte yyyy-mm-dd\n",
        "cols_date = ['Field_1','Field_2','Field_5','Field_6','Field_7','Field_8','Field_9','Field_10','Field_11'\n",
        "             ,'Field_15','Field_25','Field_32','Field_33','Field_35','Field_40','Field_43','Field_44'\n",
        "             ,'F_startDate','F_endDate','E_startDate','E_endDate','C_startDate','C_endDate','G_startDate','G_endDate'\n",
        "             ,'A_startDate','A_endDate']\n",
        "# định dạng date yyymmdd\n",
        "cols_date2 = ['ngaySinh', 'Field_34']\n",
        "# Đặc trưng dạng văn bản\n",
        "cols_docs = ['Field_46','diaChi','Field_48','Field_49','currentLocationName','homeTownName','Field_56']\n",
        "# Định danh bản ghi\n",
        "cols_id = ['id','Field_45'] +[i for i in train_set.select_dtypes(include = ['object']).columns \n",
        "                              if len(train_set[i].unique()) >=350 and i not in cols_date + cols_date2+cols_docs]\n",
        "# Đặc trưng dạng categorical\n",
        "cols_categorical = [i for i in train_set.select_dtypes(include = ['object']).columns\n",
        "                    if i not in cols_id + cols_label+cols_date2+cols_date+cols_docs]\n",
        "# Đặc trưng số\n",
        "cols_fts_num = [ i for i in test_set.select_dtypes(include=['float64','int64']).columns \n",
        "                if i not in cols_id + cols_label + cols_fts_binary + cols_date2+cols_date+cols_docs]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IZeRfJ1Yn1r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cols_categorical\n",
        "cols_date2 = ['ngaySinh', 'Field_34']"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80edhA5WEB28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Đặc trưng số có dạng như categorical\n",
        "cols_num_like_cat = [i for i in cols_fts_num if len(train_set[i].unique()) <= 15 ]\n",
        "# Đặc trưng số đã kiểm chứng\n",
        "cols_num = [i for i in cols_fts_num if i not in cols_num_like_cat]\n",
        "\n",
        "cols_categorical = cols_categorical + cols_num_like_cat\n",
        "cols_fts_num = [i for i in cols_fts_num if i not in cols_num_like_cat ]"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIiuayh8ERZ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# for i in cols_fts_num :\n",
        "#   print(i, len(train_set[i].unique()))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KBEmyXJymwc",
        "colab_type": "text"
      },
      "source": [
        "Missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pux-LyY-aCs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_set\n",
        "predict_data = test_set\n",
        "\n",
        "# Categorical: Fill giá trị null như một giá trị khác\n",
        "train_data[cols_categorical] = train_set[cols_categorical].astype('object').fillna('#NULL#').applymap(str)\n",
        "predict_data[cols_categorical] = test_set[cols_categorical].astype('object').fillna('#NULL#').applymap(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgOqbv6jbVAR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "5c560ee0-8602-4654-9548-54378ce07778"
      },
      "source": [
        "train_data[col]"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        20180107\n",
              "1             NaN\n",
              "2        20190102\n",
              "3             NaN\n",
              "4             NaN\n",
              "           ...   \n",
              "53025    20191205\n",
              "53026         NaN\n",
              "53027    20170709\n",
              "53028         NaN\n",
              "53029         NaN\n",
              "Name: Field_34, Length: 53030, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR4iXeN61WRY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Date: với dữ liệu ngày thì tạo ra các cột ngày tương ứng và cross colum => embedding để giảm chiều\n",
        "\n",
        "def trans_date_fts(df, col, format = 'yyyy-mm-dd'):\n",
        "  '''format là 'yyyy-mm-dd' hoặc 'yyyymmdd' '''\n",
        "\n",
        "  year_name = 'year_of'+col \n",
        "  month_name = 'month_of' + col\n",
        "  day_name = 'day_of' + col\n",
        "  if format == 'yyyy-mm-dd':\n",
        "    df[year_name] = df[col].apply(lambda x: str(x[:4]) if len(str(x)) >8 else '#NULL#')\n",
        "    df[month_name] = df[col].apply(lambda x: str(x[5:7]) if len(str(x)) >8 else '#NULL#')\n",
        "    df[day_name] = df[col].apply(lambda x: str(x[8:10]) if len(str(x)) >8 else '#NULL#')\n",
        "  else:\n",
        "    df[year_name] = df[col].apply(lambda x: str(x)[:4] if len(str(x)) >8 else '#NULL#')\n",
        "    df[month_name] = df[col].apply(lambda x: str(x)[4:6] if len(str(x)) >8 else '#NULL#')\n",
        "    df[day_name] = df[col].apply(lambda x: str(x)[6:8] if len(str(x)) >8 else '#NULL#')\n",
        "\n",
        "  ft1 = fc.categorical_column_with_vocabulary_list(year_name, df[year_name].unique() )\n",
        "  ft2 = fc.categorical_column_with_vocabulary_list(month_name, df[month_name].unique() )\n",
        "  ft3 = fc.categorical_column_with_vocabulary_list(day_name, df[day_name].unique() )\n",
        "  ft = fc.crossed_column([ft1, ft2, ft3], hash_bucket_size = 366)\n",
        "  ft = fc.embedding_column(ft, dimension= 64)\n",
        "\n",
        "  return df, ft, [year_name, month_name, day_name]\n",
        "\n",
        "fts_col_date = []\n",
        "date_derivated_fts = []\n",
        "for col in cols_date:\n",
        "  train_data, date_fts_list_add, date_fts_name = trans_date_fts(train_data, col,format = 'yyyy-mm-dd')\n",
        "  fts_col_date.append( date_fts_list_add )\n",
        "  date_derivated_fts.append(date_fts_name)\n",
        "for col in cols_date2:\n",
        "  train_data, date_fts_list_add, date_fts_name = trans_date_fts(train_data, col,format = 'yyyymmdd')\n",
        "  fts_col_date.append( date_fts_list_add )\n",
        "  date_derivated_fts.append(date_fts_name)\n",
        "\n",
        "for col in cols_date:\n",
        "  predict_data, date_fts_list_add, date_fts_name = trans_date_fts(predict_data, col,format = 'yyyy-mm-dd')\n",
        "for col in cols_date2:\n",
        "  predict_data, date_fts_list_add, date_fts_name = trans_date_fts(predict_data, col,format = 'yyyymmdd')\n"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uFvOxnbaFHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_data\n",
        "                                                   ,train_data['label'].values\n",
        "                                                   , stratify = train_data['label'].values \n",
        "                                                   ,test_size = 0.2\n",
        "                                                   )"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkPgKvK0ymEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Numerical: các trường chưa xử lý+ numerical fill giá trị -1\n",
        "\n",
        "# train_data[cols_fts_num] = train_set[cols_fts_num].fillna(-1)\n",
        "# predict_data[cols_fts_num] = test_set[cols_fts_num].fillna(-1)\n",
        "# X_train[cols_fts_num] = (X_train[cols_fts_num] - X_train[cols_fts_num].mean() )/ X_train[cols_fts_num].std()\n",
        "# X_test[cols_fts_num] = (X_test[cols_fts_num] - X_train[cols_fts_num].mean() )/ X_train[cols_fts_num].std()\n",
        "# predict_data[cols_fts_num] = (predict_data[cols_fts_num] - X_train[cols_fts_num].mean() )/ X_train[cols_fts_num].std()\n",
        "X_train = X_train.fillna(0)\n",
        "X_test = X_test.fillna(0)\n",
        "predict_data = predict_data.fillna(0)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYNNUzJFoprL",
        "colab_type": "text"
      },
      "source": [
        "Định nghĩa features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rI0R61duyk5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "feature_columns = []\n",
        "fts_cols = cols_fts_binary+cols_fts_num+cols_categorical +cols_date+cols_date2\n",
        "\n",
        "# Với biến binary, load trực tiếp vào model\n",
        "for col in cols_fts_binary:\n",
        "  feature_columns.append(\n",
        "      fc.numeric_column(col, dtype=tf.float32)\n",
        "  )\n",
        "# Với các biến numeric, sử dụng standard scaler + định nghĩa\n",
        "# X_train[cols_fts_num] = (X_train[cols_fts_num] - X_train[cols_fts_num].mean() )/ X_train[cols_fts_num].std()\n",
        "# X_test[cols_fts_num] = (X_test[cols_fts_num] - X_train[cols_fts_num].mean() )/ X_train[cols_fts_num].std()\n",
        "\n",
        "for col in cols_fts_num:\n",
        "  mean = X_train[col].mean()\n",
        "  std = X_train[col].std()\n",
        "  feature_columns.append(\n",
        "      fc.numeric_column(col,\n",
        "                        dtype=tf.float32\n",
        "                        #, normalizer_fn = lambda x: ( x - mean )/ std \n",
        "                        ))\n",
        "# Với các biến categorical, embed với số chiều bằng 1/10 +1 số chiều gốc\n",
        "def embed_trans(feature_name, vocab):\n",
        "  ft = fc.categorical_column_with_vocabulary_list(feature_name, vocab)\n",
        "  ft = fc.embedding_column( ft,dimension= int(len(vocab)/10) +5 )\n",
        "  return ft\n",
        "for col in cols_categorical:\n",
        "  vocabulary = train_set[col].unique()\n",
        "  feature_columns.append(\n",
        "      embed_trans(col, vocabulary)\n",
        "  )\n",
        "\n",
        "\n",
        "# Xây dựng layer\n",
        "all_fts_cols = feature_columns +fts_col_date\n",
        "feature_layer = DenseFeatures(all_fts_cols)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCOJ67grXrbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
        "def df_to_dataset(X, y, shuffle=True, batch_size=32):\n",
        "  ds = tf.data.Dataset.from_tensor_slices((X.to_dict(orient='list'), y))\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(X))\n",
        "  ds = ds.batch(batch_size)\n",
        "  return ds"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OamRsjnvEsmP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "76fd6ab3-9ab0-47de-bbd1-1a0aee1d922e"
      },
      "source": [
        "X_test.head()"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>Field_1</th>\n",
              "      <th>Field_2</th>\n",
              "      <th>Field_3</th>\n",
              "      <th>Field_4</th>\n",
              "      <th>Field_5</th>\n",
              "      <th>Field_6</th>\n",
              "      <th>Field_7</th>\n",
              "      <th>Field_8</th>\n",
              "      <th>Field_9</th>\n",
              "      <th>Field_10</th>\n",
              "      <th>Field_11</th>\n",
              "      <th>Field_12</th>\n",
              "      <th>Field_13</th>\n",
              "      <th>Field_14</th>\n",
              "      <th>Field_15</th>\n",
              "      <th>Field_16</th>\n",
              "      <th>Field_17</th>\n",
              "      <th>Field_18</th>\n",
              "      <th>Field_19</th>\n",
              "      <th>Field_20</th>\n",
              "      <th>Field_21</th>\n",
              "      <th>Field_22</th>\n",
              "      <th>Field_23</th>\n",
              "      <th>Field_24</th>\n",
              "      <th>Field_25</th>\n",
              "      <th>Field_26</th>\n",
              "      <th>Field_27</th>\n",
              "      <th>Field_28</th>\n",
              "      <th>Field_29</th>\n",
              "      <th>Field_30</th>\n",
              "      <th>Field_31</th>\n",
              "      <th>Field_32</th>\n",
              "      <th>Field_33</th>\n",
              "      <th>Field_34</th>\n",
              "      <th>Field_35</th>\n",
              "      <th>ngaySinh</th>\n",
              "      <th>namSinh</th>\n",
              "      <th>gioiTinh</th>\n",
              "      <th>...</th>\n",
              "      <th>day_ofField_43</th>\n",
              "      <th>year_ofField_44</th>\n",
              "      <th>month_ofField_44</th>\n",
              "      <th>day_ofField_44</th>\n",
              "      <th>year_ofF_startDate</th>\n",
              "      <th>month_ofF_startDate</th>\n",
              "      <th>day_ofF_startDate</th>\n",
              "      <th>year_ofF_endDate</th>\n",
              "      <th>month_ofF_endDate</th>\n",
              "      <th>day_ofF_endDate</th>\n",
              "      <th>year_ofE_startDate</th>\n",
              "      <th>month_ofE_startDate</th>\n",
              "      <th>day_ofE_startDate</th>\n",
              "      <th>year_ofE_endDate</th>\n",
              "      <th>month_ofE_endDate</th>\n",
              "      <th>day_ofE_endDate</th>\n",
              "      <th>year_ofC_startDate</th>\n",
              "      <th>month_ofC_startDate</th>\n",
              "      <th>day_ofC_startDate</th>\n",
              "      <th>year_ofC_endDate</th>\n",
              "      <th>month_ofC_endDate</th>\n",
              "      <th>day_ofC_endDate</th>\n",
              "      <th>year_ofG_startDate</th>\n",
              "      <th>month_ofG_startDate</th>\n",
              "      <th>day_ofG_startDate</th>\n",
              "      <th>year_ofG_endDate</th>\n",
              "      <th>month_ofG_endDate</th>\n",
              "      <th>day_ofG_endDate</th>\n",
              "      <th>year_ofA_startDate</th>\n",
              "      <th>month_ofA_startDate</th>\n",
              "      <th>day_ofA_startDate</th>\n",
              "      <th>year_ofA_endDate</th>\n",
              "      <th>month_ofA_endDate</th>\n",
              "      <th>day_ofA_endDate</th>\n",
              "      <th>year_ofngaySinh</th>\n",
              "      <th>month_ofngaySinh</th>\n",
              "      <th>day_ofngaySinh</th>\n",
              "      <th>year_ofField_34</th>\n",
              "      <th>month_ofField_34</th>\n",
              "      <th>day_ofField_34</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44181</th>\n",
              "      <td>44181</td>\n",
              "      <td>0</td>\n",
              "      <td>2019-11-01T11:16:00.437Z</td>\n",
              "      <td>2019-11-01T11:17:20Z</td>\n",
              "      <td>2.0</td>\n",
              "      <td>T1</td>\n",
              "      <td>2019-11-01</td>\n",
              "      <td>2019-11-01</td>\n",
              "      <td>2019-10-01</td>\n",
              "      <td>2019-12-31</td>\n",
              "      <td>2019-11-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2019-11-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3969700.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2019-11-01</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2019-11-01</td>\n",
              "      <td>2024-02-22</td>\n",
              "      <td>20191004</td>\n",
              "      <td>0</td>\n",
              "      <td>19930306.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>FEMALE</td>\n",
              "      <td>...</td>\n",
              "      <td>23</td>\n",
              "      <td>2019</td>\n",
              "      <td>06</td>\n",
              "      <td>27</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>2019</td>\n",
              "      <td>09</td>\n",
              "      <td>06</td>\n",
              "      <td>2019</td>\n",
              "      <td>09</td>\n",
              "      <td>21</td>\n",
              "      <td>1993</td>\n",
              "      <td>03</td>\n",
              "      <td>06</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29618</th>\n",
              "      <td>29618</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>...</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48677</th>\n",
              "      <td>48677</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-04-02T12:47:33.015Z</td>\n",
              "      <td>2018-04-02T12:47:33.015Z</td>\n",
              "      <td>2.0</td>\n",
              "      <td>T1</td>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>2018-01-01</td>\n",
              "      <td>2018-03-31</td>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-03-31</td>\n",
              "      <td>G8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4000000.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-01-03</td>\n",
              "      <td>2021-10-01</td>\n",
              "      <td>20170903</td>\n",
              "      <td>2018-03-31</td>\n",
              "      <td>19890317.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>MALE</td>\n",
              "      <td>...</td>\n",
              "      <td>01</td>\n",
              "      <td>2019</td>\n",
              "      <td>10</td>\n",
              "      <td>02</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>1989</td>\n",
              "      <td>03</td>\n",
              "      <td>17</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12224</th>\n",
              "      <td>12224</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>...</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>2019</td>\n",
              "      <td>08</td>\n",
              "      <td>28</td>\n",
              "      <td>2019</td>\n",
              "      <td>08</td>\n",
              "      <td>30</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33041</th>\n",
              "      <td>33041</td>\n",
              "      <td>1</td>\n",
              "      <td>2019-08-26T02:25:33.646Z</td>\n",
              "      <td>2019-08-31T20:12:27Z</td>\n",
              "      <td>1.0</td>\n",
              "      <td>GH</td>\n",
              "      <td>2018-12-24</td>\n",
              "      <td>2018-12-24</td>\n",
              "      <td>2019-01-01</td>\n",
              "      <td>2019-08-31</td>\n",
              "      <td>2018-12-24</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2019-08-31</td>\n",
              "      <td>G8</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Đ0451</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4258600.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-12-24</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2018-12-24</td>\n",
              "      <td>2023-08-01</td>\n",
              "      <td>2.01809e+07</td>\n",
              "      <td>2019-08-31</td>\n",
              "      <td>19890109.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>MALE</td>\n",
              "      <td>...</td>\n",
              "      <td>24</td>\n",
              "      <td>2019</td>\n",
              "      <td>06</td>\n",
              "      <td>26</td>\n",
              "      <td>2019</td>\n",
              "      <td>09</td>\n",
              "      <td>02</td>\n",
              "      <td>2019</td>\n",
              "      <td>09</td>\n",
              "      <td>02</td>\n",
              "      <td>2019</td>\n",
              "      <td>09</td>\n",
              "      <td>02</td>\n",
              "      <td>2019</td>\n",
              "      <td>09</td>\n",
              "      <td>04</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>#NULL#</td>\n",
              "      <td>2019</td>\n",
              "      <td>09</td>\n",
              "      <td>02</td>\n",
              "      <td>2019</td>\n",
              "      <td>09</td>\n",
              "      <td>02</td>\n",
              "      <td>2019</td>\n",
              "      <td>03</td>\n",
              "      <td>18</td>\n",
              "      <td>2019</td>\n",
              "      <td>09</td>\n",
              "      <td>13</td>\n",
              "      <td>1989</td>\n",
              "      <td>01</td>\n",
              "      <td>09</td>\n",
              "      <td>2018</td>\n",
              "      <td>09</td>\n",
              "      <td>04</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 282 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          id  label  ... month_ofField_34 day_ofField_34\n",
              "44181  44181      0  ...           #NULL#         #NULL#\n",
              "29618  29618      0  ...           #NULL#         #NULL#\n",
              "48677  48677      1  ...           #NULL#         #NULL#\n",
              "12224  12224      0  ...           #NULL#         #NULL#\n",
              "33041  33041      1  ...               09             04\n",
              "\n",
              "[5 rows x 282 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLNgUTm4X1vn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# scaler_1 = StandardScaler()\n",
        "# X_train_scaled = scaler_1.fit_transform(X_train)\n",
        "# X_test_scaled = scaler_1.transform(X_test)\n",
        "# X_predict_scaled = scaler_1.transform( test_set[cols_fts_num].fillna(0) )"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3m7hDYZX3fg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nets_2 = Sequential(\n",
        "    [\n",
        "    feature_layer,\n",
        "    BatchNormalization (),\n",
        "    Dense(512, activation ='relu'),\n",
        "    Dropout(0.25), \n",
        "    BatchNormalization (),\n",
        "    Dense(256, activation ='relu'),\n",
        "    Dropout(0.25), \n",
        "    Dense(128, activation ='relu'),\n",
        "    Dropout(0.25), \n",
        "    BatchNormalization (),\n",
        "    Dense(64, activation ='relu'),\n",
        "    Dropout(0.1), \n",
        "    Dense(16, activation ='relu'),\n",
        "    Dense(1, activation ='sigmoid')])\n",
        "nets_2.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['acc', AUC() ] ) #, Precision(), Recall()] )"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWz5G94lY81G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618
        },
        "outputId": "b7c50052-7e79-4c1c-f422-1d4378e36273"
      },
      "source": [
        "batch_size = 50 # A small batch sized is used for demonstration purposes\n",
        "train_ds = df_to_dataset(X_train, y_train, batch_size=batch_size)\n",
        "test_ds = df_to_dataset(X_test, y_test, shuffle=False, batch_size=batch_size)\n",
        "predict_ds = df_to_dataset(predict_data, predict_data['id'], shuffle=False, batch_size=batch_size)\n",
        "\n",
        "history = nets_2.fit( train_ds , epochs = 10\n",
        "                    , validation_data = test_ds)\n",
        "nets_2.summary()"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mspec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_fallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mtype_spec_from_value\u001b[0;34m(element, use_fallback)\u001b[0m\n\u001b[1;32m    465\u001b[0m   raise TypeError(\"Could not build a TypeSpec for %r with type %s\" %\n\u001b[0;32m--> 466\u001b[0;31m                   (element, type(element).__name__))\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Could not build a TypeSpec for ['2019-12-17', '2019-12-03', 0, '2019-11-29', '2019-11-04', '2019-06-26', 0, 0, '2019-11-08', '2019-11-07', '2019-12-25', '2019-11-29', 0, '2020-01-21', '2020-01-04', '2020-01-11', '2019-12-31', '2019-06-15', '2019-09-23', '2019-05-08', '2019-11-07', '2019-11-19', '2020-02-22', '2019-11-23', '2020-01-22', 0, 0, 0, '2019-11-11', '2019-09-23', 0, '2019-12-04', '2019-11-11', 0, '2019-10-05', '2019-10-31', 0, '2019-10-31', '2019-11-13', '2020-02-26', '2019-06-09', 0, '2020-01-15', 0, '2020-02-26', 0, '2019-11-09', '2019-10-08', '2020-01-06', '2019-12-08', 0, 0, '2019-11-20', '2020-01-17', '2019-09-14', '2019-11-12', '2019-09-21', '2019-12-24', 0, '2019-11-19', 0, '2019-12-09', 0, '2019-07-02', '2020-02-27', 0, 0, 0, '2020-01-22', '2019-09-29', '2019-09-07', '2019-12-14', '2019-11-06', '2019-07-20', '2019-10-06', '2020-01-05', '2019-11-20', 0, '2019-12-10', '2019-12-13', '2019-11-19', 0, 0, '2019-09-23', '2019-12-31', '2020-02-17', '2020-02-21', '2019-07-31', '2019-11-19', '2019-11-01', '2019-11-20', '2019-12-10', '2020-02-14', '2019-09-28', '2019-11-12', '2019-12-16', 0, 0, '2019-07-10', '2019-08-16', '2019-12-24', '2019-11-15', '2019-11-26', '2019-12-05', '2020-02-05', '2020-01-22', 0, '2019-10-21', '2019-11-14', 0, '2019-11-21', '2019-11-25', '2019-09-21', '2019-12-06', 0, '2019-11-08', '2020-01-16', 0, '2019-06-23', '2019-12-20', 0, '2020-02-13', '2019-11-07', '2020-01-07', '2019-09-22', '2019-09-08', 0, '2019-08-31', '20...",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-67232999e183>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m \u001b[0;31m# A small batch sized is used for demonstration purposes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtest_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredict_ds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-93-f1099e60f364>\u001b[0m in \u001b[0;36mdf_to_dataset\u001b[0;34m(X, y, shuffle, batch_size)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# A utility method to create a tf.data dataset from a Pandas Dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdf_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'list'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mfrom_tensor_slices\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    680\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m     \"\"\"\n\u001b[0;32m--> 682\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mTensorSliceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m   \u001b[0;32mclass\u001b[0m \u001b[0m_GeneratorState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, element)\u001b[0m\n\u001b[1;32m   2999\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3000\u001b[0m     \u001b[0;34m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3001\u001b[0;31m     \u001b[0melement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_element\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3002\u001b[0m     \u001b[0mbatched_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_spec_from_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3003\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_batched_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mnormalize_element\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# the value. As a fallback try converting the value to a tensor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         normalized_components.append(\n\u001b[0;32m---> 98\u001b[0;31m             ops.convert_to_tensor(t, name=\"component_%d\" % i))\n\u001b[0m\u001b[1;32m     99\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    336\u001b[0m                                          as_ref=False):\n\u001b[1;32m    337\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    262\u001b[0m   \"\"\"\n\u001b[1;32m    263\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 264\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    273\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Can't convert Python sequence with mixed types to Tensor."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6rDbZRUe6iG",
        "colab_type": "text"
      },
      "source": [
        "Dự đoán và xuất file kế quả"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP_mm9exIdAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7lxEOfQZN6H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_predict_pred= nets_2.predict(predict_ds )\n",
        "y_predict_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1TuIo4Qe_fe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res_df = pd.DataFrame({'id': test_set.id, 'label': y_predict_pred.reshape(y_predict_pred.shape[0])})\n",
        "res_df.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DZfHrliHSNEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}