{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kalapa_4student_traditional_ML.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/quanvu0996/compet/blob/master/kalapa_4student_traditional_ML.ipynb",
      "authorship_tag": "ABX9TyM10voQpkZvCagtdHweHd6Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quanvu0996/compet/blob/master/kalapa_4student_traditional_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnLk6f0nuwj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, DenseFeatures, Dropout, BatchNormalization, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow import feature_column as fc\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,roc_curve, auc\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-qcYZ8Fv1TH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c0996d90-799f-4886-da8a-749f1a6b285b"
      },
      "source": [
        "print(pd.__version__)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.5\n",
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j7u_eUMv9Zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submision_path = '/content/drive/My Drive/Data/colabs_data/kalapa_4students/simple_submission.csv'\n",
        "train_path = '/content/drive/My Drive/Data/colabs_data/kalapa_4students/train.csv'\n",
        "test_path = '/content/drive/My Drive/Data/colabs_data/kalapa_4students/test.csv'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqoJojArwAM6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "d6557519-1e1d-4717-f5b7-1823b5f2c8f6"
      },
      "source": [
        "def load_data(train_path, test_path, label_col = 'label'):\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    predict_data = pd.read_csv(test_path)\n",
        "    return train_data, predict_data\n",
        "\n",
        "train_data, predict_data = load_data( train_path, test_path )\n",
        "train_data = train_data[train_data['label'].isin( [0,1] )]\n",
        "cols = train_data.columns"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (35,43) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (34,42) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrXATFIdwCZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Nhãn\n",
        "cols_label = ['label']\n",
        "# Đặc trưng binary\n",
        "cols_fts_binary = [i for i in train_data.select_dtypes(include=['float64','int64']).columns \n",
        "                   if len(set(train_data[i].fillna(0)) - {0,1} ) == 0 and i not in cols_label]\n",
        "# định dang datte yyyy-mm-dd\n",
        "cols_date = ['Field_1','Field_2','Field_5','Field_6','Field_7','Field_8','Field_9','Field_11'\n",
        "             ,'Field_15','Field_25','Field_32','Field_33','Field_35','Field_40','Field_43','Field_44'\n",
        "             ,'F_startDate','F_endDate','E_startDate','E_endDate','C_startDate','C_endDate','G_startDate','G_endDate'\n",
        "             ,'A_startDate','A_endDate']\n",
        "# định dạng date yyymmdd\n",
        "cols_date2 = ['ngaySinh', 'Field_34']\n",
        "# Đặc trưng dạng văn bản\n",
        "cols_docs = ['Field_46','diaChi','Field_48','Field_49','currentLocationName','homeTownName','Field_56']\n",
        "# Định danh bản ghi\n",
        "cols_id = ['id','Field_45'] +[i for i in train_data.select_dtypes(include = ['object']).columns \n",
        "                              if len(train_data[i].unique()) >=350 and i not in cols_date + cols_date2+cols_docs]\n",
        "# Đặc trưng dạng categorical\n",
        "cols_categorical = [i for i in train_data.select_dtypes(include = ['object']).columns\n",
        "                    if i not in cols_id + cols_label+cols_date2+cols_date+cols_docs]\n",
        "# Đặc trưng số\n",
        "cols_fts_num = [ i for i in predict_data.select_dtypes(include=['float64','int64']).columns \n",
        "                if i not in cols_id + cols_label + cols_fts_binary + cols_date2+cols_date+cols_docs]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD5nD91PwGlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Đặc trưng số có dạng như categorical\n",
        "cols_num_like_cat = [i for i in cols_fts_num if len(train_data[i].unique()) <= 15 ]\n",
        "# Đặc trưng số đã kiểm chứng\n",
        "cols_num = [i for i in cols_fts_num if i not in cols_num_like_cat]\n",
        "\n",
        "cols_categorical = list(set(cols_categorical + cols_num_like_cat))\n",
        "cols_fts_num = [i for i in cols_fts_num if i not in cols_num_like_cat ]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VKHHN7nwqvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_data\n",
        "                                                   ,train_data['label'].values\n",
        "                                                   ,stratify = train_data['label'].values \n",
        "                                                   ,test_size = 0.2\n",
        "                                                   )"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QaLF849KxaJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bdc093cc-c9c6-44f9-a986-ebe5b777bdfe"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42424, 195)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM5JDQMY5_l6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OneHotEncoder(handle_unknown='ignore').fit(X_train[cols_categorical].astype(str).fillna('ms'))\n",
        "# X_train[cols_categorical].astype(str).info()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTqBRiQpbgvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train[cols_date].head().apply(lambda x: ( pd.to_datetime(x.apply(lambda i: str(i)[0:10]) , format='%Y-%m-%d' , errors= 'coerce')  \n",
        "#                                           - pd.to_datetime('20170101', format='%Y%m%d')).apply(lambda x: x.days)\n",
        "#                               , axis = 1)\n",
        "# X_train[cols_date].head().apply(lambda x: ( pd.to_datetime(x.apply(lambda i: str(i)[0:10]) , format=format , errors= 'coerce')  \n",
        "#                               - pd.to_datetime('20170101', format='%Y%m%d')).apply(lambda x: x.days)\n",
        "#                        , axis = 1)\n",
        "\n",
        "# (pd.to_datetime( df[col].apply(lambda x: str(x)[0:10]), format='%Y-%m-%d' , errors= 'coerce') \n",
        "#                         - pd.to_datetime('20170101', format='%Y%m%d') ).apply(lambda x: x.days)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTPdZjYZwuzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Xây dựng pipeline và fit với tree-based\n",
        "selected_columns = cols_categorical+cols_fts_num + cols_date + cols_date2\n",
        "\n",
        "class ToString(BaseEstimator, TransformerMixin):\n",
        "  '''Def 1 trans để convert các cột dạng số như categorical thành dạng cat => dùng được onehot'''\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "  def transform(self, X, y = None):\n",
        "    X_ = X.copy() # creating a copy to avoid changes to original dataset\n",
        "    X_ = X_.astype(str)\n",
        "    return X_\n",
        "\n",
        "class DateToNum(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, format = '%Y-%m-%d' ):\n",
        "    self.format = format\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "  def transform(self, X, y = None):\n",
        "    X_ = X.copy() # creating a copy to avoid changes to original dataset\n",
        "    X_ = X_.apply(lambda x: ( pd.to_datetime(x.apply(lambda i: str(i)[0:10]) , format= self.format , errors= 'coerce')  \n",
        "                              - pd.to_datetime('20170101', format='%Y%m%d')).apply(lambda x: x.days)\n",
        "                       , axis = 1)\n",
        "    return X_\n",
        "\n",
        "categorical_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing'))\n",
        "    , ('to_string', ToString())\n",
        "    , ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "numerical_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean'))\n",
        "    # , ('standard', StandardScaler()) # Với tree thì không cần standard\n",
        "])\n",
        "\n",
        "datetime_pipe1 = Pipeline([\n",
        "    ('datetime1', DateToNum(format='%Y-%m-%d'))\n",
        "    # , ('standard', StandardScaler()) # Với tree thì không cần standard\n",
        "    , ('imputer', SimpleImputer(strategy='mean'))\n",
        "])\n",
        "\n",
        "datetime_pipe2 = Pipeline([\n",
        "    ('datetime2', DateToNum(format='%Y%m%d'))\n",
        "    # , ('standard', StandardScaler()) # Với tree thì không cần standard\n",
        "    , ('imputer', SimpleImputer(strategy='mean'))\n",
        "])\n",
        "\n",
        "preprocessing = ColumnTransformer(\n",
        "    [\n",
        "     ('cat', categorical_pipe, cols_categorical),\n",
        "     ('num', numerical_pipe, cols_fts_num), \n",
        "     ('date1', datetime_pipe1, cols_date),\n",
        "     ('date2', datetime_pipe2, cols_date2)\n",
        "     ])\n",
        "\n",
        "rf = Pipeline([\n",
        "    ('preprocess', preprocessing),\n",
        "    ('classifier', GradientBoostingClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "rf.fit(X_train[selected_columns], y_train)\n",
        "\n",
        "y_pred_rt = rf.predict_proba(X_test[selected_columns])[:, 1]\n",
        "fpr_rt_lm, tpr_rt_lm, _ = roc_curve(y_test, y_pred_rt)\n",
        "print('AUC: ', auc(fpr_rt_lm, tpr_rt_lm))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_rt_lm, tpr_rt_lm, label='RT + LR')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC6TfPN1i0wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train[cols_date].apply(lambda x: ( pd.to_datetime(x.apply(lambda i: str(i)[0:10]) , format=format , errors= 'coerce')  \n",
        "#                               - pd.to_datetime('20170101', format='%Y%m%d')).apply(lambda x: x.days)\n",
        "#                        , axis = 1)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iODPgpHW9N8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # SVM\n",
        "# categorical_pipe = Pipeline([\n",
        "#     ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "# ])\n",
        "# numerical_pipe = Pipeline([\n",
        "#     ('imputer', SimpleImputer(strategy='mean'))\n",
        "#     , ('standard', StandardScaler()) # Với tree thì không cần standard\n",
        "# ])\n",
        "\n",
        "# preprocessing = ColumnTransformer(\n",
        "#     [('cat', categorical_pipe, cols_categorical),\n",
        "#      ('num', numerical_pipe, cols_fts_num)])\n",
        "\n",
        "# pipeline = Pipeline([\n",
        "#     ('preprocess', preprocessing),\n",
        "#     ('classifier', SVC(probability = True))\n",
        "# ])\n",
        "# pipeline.fit(X_train, y_train)\n",
        "\n",
        "# y_pred_rt = pipeline.predict_proba(X_test)[:, 1]\n",
        "# fpr_rt_lm, tpr_rt_lm, _ = roc_curve(y_test, y_pred_rt)\n",
        "# print('AUC: ', auc(fpr_rt_lm, tpr_rt_lm))\n",
        "\n",
        "# plt.plot([0, 1], [0, 1], 'k--')\n",
        "# plt.plot(fpr_rt_lm, tpr_rt_lm, label='RT + LR')\n",
        "# plt.xlabel('False positive rate')\n",
        "# plt.ylabel('True positive rate')\n",
        "# plt.title('ROC curve')\n",
        "# plt.legend(loc='best')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPs4HgzMCgWp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "997e1254-ea9b-462f-f914-197cc6c8661b"
      },
      "source": [
        "# TF nets\n",
        "class DenseTransformer(TransformerMixin):\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None, **fit_params):\n",
        "        return X.todense()\n",
        "\n",
        "categorical_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('to_string', ToString()),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "numerical_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean'))\n",
        "    # , ('standard', StandardScaler()) # Với tree thì không cần standard\n",
        "])\n",
        "\n",
        "preprocessing = ColumnTransformer(\n",
        "    [('cat', categorical_pipe, cols_categorical),\n",
        "     ('num', numerical_pipe, cols_fts_num)])\n",
        "\n",
        "def building_net_func():\n",
        "  net = Sequential(\n",
        "      [\n",
        "      BatchNormalization (),\n",
        "      Dense(1024, activation ='relu', kernel_initializer = 'he_normal'),\n",
        "      Dropout(0.5), \n",
        "      BatchNormalization (),\n",
        "      Dense(128, activation ='relu', kernel_initializer = 'he_normal'),\n",
        "      Dropout(0.25), \n",
        "      # BatchNormalization (),\n",
        "      # Dense(64, activation ='relu', kernel_initializer = 'he_normal'),\n",
        "      # Dropout(0.25), \n",
        "      # BatchNormalization (),\n",
        "      Dense(16, activation ='relu', kernel_initializer = 'he_normal'),\n",
        "      BatchNormalization (),\n",
        "      Dense(1, activation ='sigmoid', kernel_initializer = 'he_normal')])\n",
        "  net.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = [ AUC() ] )\n",
        "  return net\n",
        "\n",
        "net = KerasRegressor(build_fn= building_net_func, verbose = 1)\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocess', preprocessing),\n",
        "    ('todense', DenseTransformer()),\n",
        "    ('classifier', net)\n",
        "])\n",
        "pipeline.fit(\n",
        "    pd.concat([X_train, X_test])[selected_columns],\n",
        "    np.concatenate( [y_train, y_test])\n",
        "    , classifier__epochs = 8\n",
        "    , classifier__batch_size = 1024\n",
        "    , classifier__validation_split = 0.2)\n",
        "\n",
        "y_pred_rt = pipeline.predict(X_test)\n",
        "fpr_rt_lm, tpr_rt_lm, _ = roc_curve(y_test, y_pred_rt)\n",
        "print('AUC: ', auc(fpr_rt_lm, tpr_rt_lm))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_rt_lm, tpr_rt_lm, label='RT + LR')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ff23caab4e24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TF nets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDenseTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTransformerMixin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TransformerMixin' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvh36b5dIOjE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8109ca33-4a86-4dd1-f96a-778fec9a791a"
      },
      "source": [
        "prediction = pipeline.predict(predict_data[selected_columns])\n",
        "res_df = pd.DataFrame({'id': predict_data.id, 'label': prediction})\n",
        "res_df.to_csv('submission_net.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "637/637 [==============================] - 2s 3ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCi6u6n10qAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ohe = (rf.named_steps['preprocess']\n",
        "#          .named_transformers_['cat']\n",
        "#          .named_steps['onehot'])\n",
        "# feature_names = ohe.get_feature_names(input_features=cols_categorical)\n",
        "# feature_names = np.r_[feature_names, cols_fts_num]\n",
        "\n",
        "# tree_feature_importances = (\n",
        "#     rf.named_steps['classifier'].feature_importances_)\n",
        "# sorted_idx = tree_feature_importances.argsort()\n",
        "\n",
        "# fts_im_num = 15\n",
        "# y_ticks = np.arange(0, fts_im_num)\n",
        "# fig, ax = plt.subplots()\n",
        "# ax.barh(y_ticks, tree_feature_importances[sorted_idx[:fts_im_num]])\n",
        "# ax.set_yticklabels(feature_names[sorted_idx[:fts_im_num]])\n",
        "# ax.set_yticks(y_ticks)\n",
        "# ax.set_title(\"Random Forest Feature Importances (MDI)\")\n",
        "# fig.tight_layout()\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9LsZO6v2aiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sorted_idx[:15]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWrKJNfU9aDO",
        "colab_type": "text"
      },
      "source": [
        "Dự đoán kết quả"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D41J0WI22g05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = rf.predict_proba(predict_data[selected_columns])[:, 1]\n",
        "res_df = pd.DataFrame({'id': predict_data.id, 'label': prediction})\n",
        "res_df.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRAr9z2Y9qYa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5f3de056-f8ac-4b19-e98e-e5025385554b"
      },
      "source": [
        "prediction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.24803742, 0.31890366, 0.4028687 , ..., 0.10729143, 0.26460362,\n",
              "       0.19883522])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    }
  ]
}