{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kalapa_4student_traditional_ML.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/quanvu0996/compet/blob/master/kalapa_4student_traditional_ML_ordinal_encoder.ipynb",
      "authorship_tag": "ABX9TyP2HzbjENaXcTnsCLUJ89FM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quanvu0996/compet/blob/master/kalapa_4student_traditional_ML_ordinal_encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnLk6f0nuwj-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d5a6e106-b4a0-4044-bf58-72f82a2db030"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, DenseFeatures, Dropout, BatchNormalization, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow import feature_column as fc\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,roc_curve, auc\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "import xgboost as xgb\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-qcYZ8Fv1TH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "0692c5f2-4a53-46c7-8998-e21513efc774"
      },
      "source": [
        "print(pd.__version__)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.5\n",
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j7u_eUMv9Zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submision_path = '/content/drive/My Drive/Data/colabs_data/kalapa_4students/simple_submission.csv'\n",
        "train_path = '/content/drive/My Drive/Data/colabs_data/kalapa_4students/train.csv'\n",
        "test_path = '/content/drive/My Drive/Data/colabs_data/kalapa_4students/test.csv'\n",
        "\n",
        "added_data_path= '/content/drive/My Drive/Data/colabs_data/kalapa_4students/exdata.txt'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqoJojArwAM6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "3c5ff9d5-9634-417b-cb89-efcf65ddb681"
      },
      "source": [
        "def load_data(train_path, test_path, label_col = 'label'):\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    predict_data = pd.read_csv(test_path)\n",
        "    return train_data, predict_data\n",
        "\n",
        "train_data, predict_data = load_data( train_path, test_path )\n",
        "train_data = train_data[train_data['label'].isin( [0,1] )].replace('notfound','missing')\n",
        "predict_data = predict_data.replace('notfound','missing')\n",
        "cols = train_data.columns"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (35,43) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (34,42) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbBLkOqGN7F4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "929225ae-72cf-40b7-dc6b-923ed66ee6bf"
      },
      "source": [
        "# train_data.merge()\n",
        "added_data = pd.read_csv(added_data_path, sep='\\t', encoding='utf-8', names = ['homeTownState', 'area', 'population', 'pop_density'])\n",
        "added_data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>homeTownState</th>\n",
              "      <th>area</th>\n",
              "      <th>population</th>\n",
              "      <th>pop_density</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>province</td>\n",
              "      <td>area</td>\n",
              "      <td>population</td>\n",
              "      <td>pop_density</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hà Nội</td>\n",
              "      <td>3358.6</td>\n",
              "      <td>8093.9</td>\n",
              "      <td>2410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Vĩnh Phúc</td>\n",
              "      <td>1235.9</td>\n",
              "      <td>1154.8</td>\n",
              "      <td>934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Bắc Ninh</td>\n",
              "      <td>822.7</td>\n",
              "      <td>1378.6</td>\n",
              "      <td>1676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quảng Ninh</td>\n",
              "      <td>6178.2</td>\n",
              "      <td>1324.8</td>\n",
              "      <td>214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>Cần Thơ</td>\n",
              "      <td>1439</td>\n",
              "      <td>1236</td>\n",
              "      <td>859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>Hậu Giang</td>\n",
              "      <td>1621.7</td>\n",
              "      <td>732.2</td>\n",
              "      <td>451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>Sóc Trăng</td>\n",
              "      <td>3311.9</td>\n",
              "      <td>1199.5</td>\n",
              "      <td>362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>Bạc Liêu</td>\n",
              "      <td>2669</td>\n",
              "      <td>908.2</td>\n",
              "      <td>340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>Cà Mau</td>\n",
              "      <td>5221.2</td>\n",
              "      <td>1194.3</td>\n",
              "      <td>229</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   homeTownState    area  population  pop_density\n",
              "0       province    area  population  pop_density\n",
              "1         Hà Nội  3358.6      8093.9         2410\n",
              "2      Vĩnh Phúc  1235.9      1154.8          934\n",
              "3       Bắc Ninh   822.7      1378.6         1676\n",
              "4     Quảng Ninh  6178.2      1324.8          214\n",
              "..           ...     ...         ...          ...\n",
              "60       Cần Thơ    1439        1236          859\n",
              "61     Hậu Giang  1621.7       732.2          451\n",
              "62     Sóc Trăng  3311.9      1199.5          362\n",
              "63      Bạc Liêu    2669       908.2          340\n",
              "64        Cà Mau  5221.2      1194.3          229\n",
              "\n",
              "[65 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oprz_imExUEA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# unique_check = train_data['homeTownState'].unique()\n",
        "# val_check = train_data.groupby(['homeTownState'])['id'].count().sort_values(ascending=False)\n",
        "# val_check['Thanh Hóa Province']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TT9zCpWXTtO",
        "colab_type": "text"
      },
      "source": [
        "Clean data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSYdoBTpXXx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vals_homeTownState = { 'Hanoi' : 'Hà Nội' , \n",
        "'Ho Chi Minh City' : 'TP.Hồ Chí Minh' , \n",
        "'Thanh Hóa Province' : 'Thanh Hoá' , \n",
        "'Nghệ An Province' : 'Nghệ An' , \n",
        "'Đồng Nai Province' : 'Đồng Nai' , \n",
        "'Haiphong' : 'Hải Phòng' , \n",
        "'Khánh Hòa Province' : 'Khánh Hoà' , \n",
        "'Thái Bình Province' : 'Thái Bình' , \n",
        "'Bắc Giang Province' : 'Bắc Giang' , \n",
        "'Hà Tĩnh Province' : 'Hà Tĩnh' , \n",
        "'Bình Định Province' : 'Bình Định' , \n",
        "'Nam Định Province' : 'Nam Định' , \n",
        "'Bắc Ninh Province' : 'Bắc Ninh' , \n",
        "'Quảng Ngãi Province' : 'Quảng Ngãi' , \n",
        "'Hải Dương Province' : 'Hải Dương' , \n",
        "'Quảng Nam Province' : 'Quảng Nam' , \n",
        "'Thái Nguyên Province' : 'Thái Nguyên' , \n",
        "'An Giang Province' : 'An Giang' , \n",
        "'Cần Thơ' : 'Cần Thơ' , \n",
        "'Đắk Lắk Province' : 'Đắk Lắk' , \n",
        "'Da Nang' : 'Đà Nẵng' , \n",
        "'Tiền Giang Province' : 'Tiền Giang' , \n",
        "'Phú Thọ Province' : 'Phú Thọ' , \n",
        "'Quảng Ninh Province' : 'Quảng Ninh' , \n",
        "'Ninh Bình Province' : 'Ninh Bình' , \n",
        "'Thừa Thiên–Huế Province' : 'Thừa Thiên Huế' , \n",
        "'Bến Tre Province' : 'Bến Tre' , \n",
        "'Hưng Yên Province' : 'Hưng Yên' , \n",
        "'Bà Rịa–Vũng Tàu Province' : 'Bà Rịa - Vũng Tàu' , \n",
        "'Kiên Giang Province' : 'Kiên Giang' , \n",
        "'Quảng Trị Province' : 'Quảng Trị' , \n",
        "'Đồng Tháp Province' : 'Đồng Tháp' , \n",
        "'Tây Ninh Province' : 'Tây Ninh' , \n",
        "'Sóc Trăng Province' : 'Sóc Trăng' , \n",
        "'Lâm Đồng Province' : 'Lâm Đồng' , \n",
        "'Lạng Sơn Province' : 'Lạng Sơn' , \n",
        "'Bình Thuận Province' : 'Bình Thuận' , \n",
        "'Gia Lai Province' : 'Gia Lai' , \n",
        "'Sơn La Province' : 'Sơn La' , \n",
        "'Cà Mau Province' : 'Cà Mau' , \n",
        "'Tuyên Quang Province' : 'Tuyên Quang' , \n",
        "'Quảng Bình Province' : 'Quảng Bình' , \n",
        "'Vĩnh Long Province' : 'Vĩnh Long' , \n",
        "'Long An Province' : 'Long An' , \n",
        "'Yên Bái Province' : 'Yên Bái' , \n",
        "'Bạc Liêu Province' : 'Bạc Liêu' , \n",
        "'Hòa Bình Province' : 'Hoà Bình' , \n",
        "'Trà Vinh Province' : 'Trà Vinh' , \n",
        "'Bình Dương Province' : 'Bình Dương' , \n",
        "'Phú Yên Province' : 'Phú Yên' , \n",
        "'Hà Nam Province' : 'Hà Nam' , \n",
        "'Vĩnh Phúc Province' : 'Vĩnh Phúc' , \n",
        "'Lào Cai Province' : 'Lào Cai' , \n",
        "'Điện Biên Province' : 'Điện Biên' , \n",
        "'Ninh Thuận Province' : 'Ninh Thuận' , \n",
        "'Cao Bằng Province' : 'Cao Bằng' , \n",
        "'Hà Giang Province' : 'Hà Giang' , \n",
        "'Bắc Kạn Province' : 'Bắc Kạn' , \n",
        "'Kon Tum Province' : 'Kon Tum' , \n",
        "'Hậu Giang Province' : 'Hậu Giang' , \n",
        "'Sarawak' : 'Sarawak' , \n",
        "'Đắk Nông Province' : 'Đắk Nông' , \n",
        "'Seoul' : 'Seoul' , \n",
        "'Bình Phước Province' : 'Bình Phước' , \n",
        "'New York' : 'New York' , \n",
        "'England' : 'England' , \n",
        "'Lai Châu Province' : 'Lai Châu' , \n",
        "'California' : 'California' , \n",
        "'Hong Kong' : 'Hong Kong' , \n",
        "'Orientale' : 'Orientale' , \n",
        "'Dubai' : 'Dubai' , \n",
        "'Guangdong' : 'Guangdong' , \n",
        "'Île-de-France' : 'Île-de-France' }"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWgquweLS89F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data['homeTownState'] = train_data['homeTownState'].fillna('other').map(vals_homeTownState ).fillna('Foreign')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krPJIye5YMWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n",
        "#     display(train_data.groupby(['homeTownState'])['label'].count().sort_values())"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "betxmRCWZRzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = train_data.merge(added_data, how = 'left', on = 'homeTownState')\n",
        "predict_data = predict_data.merge(added_data, how = 'left', on = 'homeTownState')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwZpKbEsg4ul",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data[['homeTownState', 'area', 'population', 'pop_density']].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrXATFIdwCZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Nhãn\n",
        "cols_label = ['label']\n",
        "# Đặc trưng binary\n",
        "cols_fts_binary = [i for i in train_data.select_dtypes(include=['float64','int64']).columns \n",
        "                   if len(set(train_data[i].fillna(0)) - {0,1} ) == 0 and i not in cols_label]\n",
        "# định dang datte yyyy-mm-dd\n",
        "cols_date = ['Field_1','Field_2','Field_5','Field_6','Field_7','Field_8','Field_9','Field_11'\n",
        "             ,'Field_15','Field_25','Field_32','Field_33','Field_35','Field_40','Field_43','Field_44'\n",
        "             ,'F_startDate','F_endDate','E_startDate','E_endDate','C_startDate','C_endDate','G_startDate','G_endDate'\n",
        "             ,'A_startDate','A_endDate']\n",
        "# định dạng date yyymmdd\n",
        "cols_date2 = ['ngaySinh', 'Field_34']\n",
        "# Đặc trưng dạng văn bản\n",
        "cols_docs = ['Field_46','diaChi','Field_48','Field_49','currentLocationName','homeTownName','Field_56']\n",
        "# Định danh bản ghi\n",
        "cols_id = ['id','Field_45'] +[i for i in train_data.select_dtypes(include = ['object']).columns \n",
        "                              if len(train_data[i].unique()) >=350 and i not in cols_date + cols_date2+cols_docs]\n",
        "# Đặc trưng dạng categorical\n",
        "cols_categorical = [i for i in train_data.select_dtypes(include = ['object']).columns\n",
        "                    if i not in cols_id + cols_label+cols_date2+cols_date+cols_docs]\n",
        "# Đặc trưng số\n",
        "cols_fts_num = [ i for i in predict_data.select_dtypes(include=['float64','int64']).columns \n",
        "                if i not in cols_id + cols_label + cols_fts_binary + cols_date2+cols_date+cols_docs]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD5nD91PwGlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Đặc trưng số có dạng như categorical\n",
        "cols_num_like_cat = [i for i in cols_fts_num if len(train_data[i].unique()) <= 15 ]\n",
        "# Đặc trưng số đã kiểm chứng\n",
        "cols_num = [i for i in cols_fts_num if i not in cols_num_like_cat]\n",
        "\n",
        "cols_categorical = list(set(cols_categorical + cols_num_like_cat))\n",
        "cols_fts_num = [i for i in cols_fts_num if i not in cols_num_like_cat ]"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VKHHN7nwqvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_data\n",
        "                                                   ,train_data['label'].values\n",
        "                                                   ,stratify = train_data['label'].values \n",
        "                                                   ,test_size = 0.2\n",
        "                                                   )"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QaLF849KxaJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f03f3787-559a-4241-e162-3d43bcd37b38"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42424, 198)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM5JDQMY5_l6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OneHotEncoder(handle_unknown='ignore').fit(X_train[cols_categorical].astype(str).fillna('ms'))\n",
        "# X_train[cols_categorical].astype(str).info()\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTqBRiQpbgvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train[cols_date].head().apply(lambda x: ( pd.to_datetime(x.apply(lambda i: str(i)[0:10]) , format='%Y-%m-%d' , errors= 'coerce')  \n",
        "#                                           - pd.to_datetime('20170101', format='%Y%m%d')).apply(lambda x: x.days)\n",
        "#                               , axis = 1)\n",
        "# X_train[cols_date].head().apply(lambda x: ( pd.to_datetime(x.apply(lambda i: str(i)[0:10]) , format=format , errors= 'coerce')  \n",
        "#                               - pd.to_datetime('20170101', format='%Y%m%d')).apply(lambda x: x.days)\n",
        "#                        , axis = 1)\n",
        "\n",
        "# (pd.to_datetime( df[col].apply(lambda x: str(x)[0:10]), format='%Y-%m-%d' , errors= 'coerce') \n",
        "#                         - pd.to_datetime('20170101', format='%Y%m%d') ).apply(lambda x: x.days)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-pFSxh8C1FQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lấy list value cho ordinalencoder\n",
        "categories_val = []\n",
        "for i in cols_categorical:\n",
        "  categories_val.append(list( \n",
        "      pd.concat([train_data[i], predict_data[i]]).fillna('missing').apply(lambda x: str(x)).drop_duplicates( \n",
        "  ).sort_values().values) )"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtM-G8A7fGQb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 656
        },
        "outputId": "219f4901-dbcb-4217-b42d-df122becefa8"
      },
      "source": [
        "cols_fts_num"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Field_19',\n",
              " 'Field_20',\n",
              " 'Field_23',\n",
              " 'Field_27',\n",
              " 'Field_28',\n",
              " 'Field_29',\n",
              " 'Field_59',\n",
              " 'Field_60',\n",
              " 'Field_67',\n",
              " 'Field_69',\n",
              " 'Field_70',\n",
              " 'Field_71',\n",
              " 'Field_72',\n",
              " 'Field_74',\n",
              " 'Field_77',\n",
              " 'friendCount',\n",
              " 'subscriberCount',\n",
              " 'currentLocationLocationId',\n",
              " 'currentLocationLatitude',\n",
              " 'currentLocationLongitude',\n",
              " 'homeTownLocationId',\n",
              " 'homeTownLatitude',\n",
              " 'homeTownLongitude',\n",
              " 'numOrg',\n",
              " 'F_numQuery',\n",
              " 'E_numQuery',\n",
              " 'C_numQuery',\n",
              " 'A_numQuery',\n",
              " 'summary_6m',\n",
              " 'summary_3m',\n",
              " 'summary_1m',\n",
              " 'summary_1w',\n",
              " 'Field_78',\n",
              " 'Field_79',\n",
              " 'Field_80',\n",
              " 'Field_81']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtp_oceSbdZl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6e458766-7548-4eab-e5c0-699016e8e52e"
      },
      "source": [
        "for i in cols_fts_binary:\n",
        "  print(train_data.fillna(-1).groupby([i])['label'].agg(['mean', 'count']))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              mean  count\n",
            "Field_13                 \n",
            "-1.0      0.348285  27466\n",
            " 1.0      0.282820  25564\n",
            "              mean  count\n",
            "Field_14                 \n",
            "-1.0      0.348285  27466\n",
            " 1.0      0.282820  25564\n",
            "              mean  count\n",
            "Field_16                 \n",
            "-1.0      0.348285  27466\n",
            " 1.0      0.282820  25564\n",
            "              mean  count\n",
            "Field_17                 \n",
            "-1.0      0.348285  27466\n",
            " 1.0      0.282820  25564\n",
            "              mean  count\n",
            "Field_24                 \n",
            "-1.0      0.348285  27466\n",
            " 1.0      0.282820  25564\n",
            "              mean  count\n",
            "Field_26                 \n",
            "-1.0      0.348285  27466\n",
            " 1.0      0.282820  25564\n",
            "              mean  count\n",
            "Field_30                 \n",
            "-1.0      0.348285  27466\n",
            " 1.0      0.282820  25564\n",
            "              mean  count\n",
            "Field_31                 \n",
            "-1.0      0.348285  27466\n",
            " 1.0      0.282820  25564\n",
            "              mean  count\n",
            "Field_37                 \n",
            "-1.0      0.348285  27466\n",
            " 1.0      0.282820  25564\n",
            "              mean  count\n",
            "Field_39                 \n",
            "-1.0      0.348285  27466\n",
            " 0.0      0.325323   4869\n",
            " 1.0      0.272820  20695\n",
            "              mean  count\n",
            "Field_41                 \n",
            "-1.0      0.348285  27466\n",
            " 0.0      0.325711   6079\n",
            " 1.0      0.269438  19485\n",
            "              mean  count\n",
            "Field_42                 \n",
            "-1.0      0.348285  27466\n",
            " 0.0      0.331413   6424\n",
            " 1.0      0.266510  19140\n",
            "              mean  count\n",
            "Field_50                 \n",
            "-1.0      0.348285  27466\n",
            " 0.0      0.500000      6\n",
            " 1.0      0.282769  25558\n",
            "              mean  count\n",
            "Field_51                 \n",
            "-1.0      0.348285  27466\n",
            " 0.0      0.250000      4\n",
            " 1.0      0.282825  25560\n",
            "              mean  count\n",
            "Field_52                 \n",
            "-1.0      0.348285  27466\n",
            " 1.0      0.282820  25564\n",
            "              mean  count\n",
            "Field_53                 \n",
            "-1.0      0.348285  27466\n",
            " 0.0      0.282832  25478\n",
            " 1.0      0.279070     86\n",
            "              mean  count\n",
            "Field_57                 \n",
            "-1.0      0.348285  27466\n",
            " 1.0      0.282820  25564\n",
            "              mean  count\n",
            "Field_73                 \n",
            "-1.0      0.253690  23919\n",
            " 0.0      0.401596    376\n",
            " 1.0      0.368088  28735\n",
            "                mean  count\n",
            "partner0_A                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.338850  25256\n",
            " 1.0        0.310418  23027\n",
            "                mean  count\n",
            "partner0_B                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner0_C                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.340062  26901\n",
            " 1.0        0.306707  21382\n",
            "                mean  count\n",
            "partner0_D                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.339386  24727\n",
            " 1.0        0.310494  23556\n",
            "                mean  count\n",
            "partner0_E                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.339426  24730\n",
            " 1.0        0.310449  23553\n",
            "                mean  count\n",
            "partner0_F                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.339481  24726\n",
            " 1.0        0.310396  23557\n",
            "                mean  count\n",
            "partner0_G                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.335242  26891\n",
            " 1.0        0.312780  21392\n",
            "                mean  count\n",
            "partner0_H                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325719  47759\n",
            " 1.0        0.286260    524\n",
            "                mean  count\n",
            "partner0_K                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner0_L                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner1_A                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.349321  24310\n",
            " 1.0        0.300922  23973\n",
            "                mean  count\n",
            "partner1_B                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner1_C                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325389  48250\n",
            " 1.0        0.181818     33\n",
            "                mean  count\n",
            "partner1_D                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner1_E                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner1_F                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner1_G                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.326724  46250\n",
            " 1.0        0.292671   2033\n",
            "                mean  count\n",
            "partner1_H                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.326363  47677\n",
            " 1.0        0.240924    606\n",
            "                mean  count\n",
            "partner1_K                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner1_L                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner2_A                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.324620  46784\n",
            " 1.0        0.346231   1499\n",
            "                mean  count\n",
            "partner2_B                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner2_C                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.324635  46788\n",
            " 1.0        0.345819   1495\n",
            "                mean  count\n",
            "partner2_D                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.324659  46806\n",
            " 1.0        0.345295   1477\n",
            "                mean  count\n",
            "partner2_E                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.324620  46784\n",
            " 1.0        0.346231   1499\n",
            "                mean  count\n",
            "partner2_F                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.324613  46785\n",
            " 1.0        0.346462   1498\n",
            "                mean  count\n",
            "partner2_G                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner2_H                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.324665  46799\n",
            " 1.0        0.345013   1484\n",
            "                mean  count\n",
            "partner2_K                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner2_L                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner3_A                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.312185  31776\n",
            " 1.0        0.350518  16507\n",
            "                mean  count\n",
            "partner3_B                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner3_C                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner3_D                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.340340  38106\n",
            " 1.0        0.268940  10177\n",
            "                mean  count\n",
            "partner3_E                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325412  48222\n",
            " 1.0        0.229508     61\n",
            "                mean  count\n",
            "partner3_F                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner3_G                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner3_H                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner3_K                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner3_L                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner4_A                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner4_B                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner4_C                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner4_D                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner4_E                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner4_F                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner4_G                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner4_H                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner4_K                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner4_L                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.311414  33486\n",
            " 1.0        0.356694  14797\n",
            "                mean  count\n",
            "partner5_A                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.310530  36003\n",
            " 1.0        0.368567  12280\n",
            "                mean  count\n",
            "partner5_B                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner5_C                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner5_D                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325248  48277\n",
            " 1.0        0.666667      6\n",
            "                mean  count\n",
            "partner5_E                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325248  48277\n",
            " 1.0        0.666667      6\n",
            "                mean  count\n",
            "partner5_F                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325248  48277\n",
            " 1.0        0.666667      6\n",
            "                mean  count\n",
            "partner5_G                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325283  48281\n",
            " 1.0        0.500000      2\n",
            "                mean  count\n",
            "partner5_H                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner5_K                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n",
            "                mean  count\n",
            "partner5_L                 \n",
            "-1.0        0.229619   4747\n",
            " 0.0        0.325290  48283\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9-MlSdSTSW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# selected_columns"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTPdZjYZwuzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Xây dựng pipeline và fit với tree-based\n",
        "selected_columns = cols_categorical+cols_fts_num + cols_date + cols_date2 + cols_fts_binary\n",
        "\n",
        "class ToString(BaseEstimator, TransformerMixin):\n",
        "  '''Def 1 trans để convert các cột dạng số như categorical thành dạng cat => dùng được onehot'''\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "  def transform(self, X, y = None):\n",
        "    X_ = X.copy() # creating a copy to avoid changes to original dataset\n",
        "    X_ = X_.astype(str)\n",
        "    return X_\n",
        "\n",
        "class DateToNum(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, format = '%Y-%m-%d' ):\n",
        "    self.format = format\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "  def transform(self, X, y = None):\n",
        "    X_ = X.copy() # creating a copy to avoid changes to original dataset\n",
        "    X_ = X_.apply(lambda x: ( pd.to_datetime(x.apply(lambda i: str(i)[0:10]) , format= self.format , errors= 'coerce')  \n",
        "                              - pd.to_datetime('20170101', format='%Y%m%d')).apply(lambda x: x.days)\n",
        "                       , axis = 1)\n",
        "    for i in X_.columns:\n",
        "      X_[i+'year_as_number'] = pd.to_datetime(X_[i].apply(lambda i: str(i)[0:10])\n",
        "                                        , format= self.format , errors= 'coerce').dt.year -2010\n",
        "      X_[i+'month_as_number'] = pd.to_datetime(X_[i].apply(lambda i: str(i)[0:10])\n",
        "                                        , format= self.format , errors= 'coerce').dt.month\n",
        "      X_[i+'day_as_number'] = pd.to_datetime(X_[i].apply(lambda i: str(i)[0:10])\n",
        "                                        , format= self.format , errors= 'coerce').dt.day\n",
        "    return X_\n",
        "\n",
        "categorical_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing'))\n",
        "    , ('to_string', ToString())\n",
        "    , ('onehot', OrdinalEncoder(categories=categories_val))\n",
        "])\n",
        "numerical_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean'))\n",
        "    # , ('standard', StandardScaler()) # Với tree thì không cần standard\n",
        "])\n",
        "\n",
        "binary_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value= -1 ))\n",
        "    # , ('standard', StandardScaler()) # Với tree thì không cần standard\n",
        "])\n",
        "\n",
        "datetime_pipe1 = Pipeline([\n",
        "    ('datetime1', DateToNum(format='%Y-%m-%d'))\n",
        "    # , ('standard', StandardScaler()) # Với tree thì không cần standard\n",
        "    , ('imputer', SimpleImputer(strategy='mean'))\n",
        "])\n",
        "\n",
        "datetime_pipe2 = Pipeline([\n",
        "    ('datetime2', DateToNum(format='%Y%m%d'))\n",
        "    # , ('standard', StandardScaler()) # Với tree thì không cần standard\n",
        "    , ('imputer', SimpleImputer(strategy='mean'))\n",
        "])\n",
        "\n",
        "preprocessing = ColumnTransformer(\n",
        "    [\n",
        "     ('cat', categorical_pipe, cols_categorical),\n",
        "     ('num', numerical_pipe, cols_fts_num), \n",
        "     ('binary', binary_pipe, cols_fts_binary), \n",
        "     ('date1', datetime_pipe1, cols_date),\n",
        "     ('date2', datetime_pipe2, cols_date2)\n",
        "     ])\n",
        "\n",
        "#xgb.XGBRegressor(objective=\"reg:linear\", random_state=42, n_estimators =64, max_depth =7)\n",
        "# LGBMClassifier(\n",
        "#             nthread=4,\n",
        "#             n_estimators=10000,\n",
        "#             learning_rate=0.02,\n",
        "#             num_leaves=128,\n",
        "#             colsample_bytree=0.9497036,\n",
        "#             subsample=0.8715623,\n",
        "#             max_depth=8,\n",
        "#             reg_alpha=0.041545473,\n",
        "#             reg_lambda=0.0735294,\n",
        "#             min_split_gain=0.0222415,\n",
        "#             min_child_weight=39.3259775,\n",
        "#             silent=-1,\n",
        "#             verbose=-1\n",
        "#         )\n",
        "model = GradientBoostingClassifier(random_state=42, max_depth = 7 ) # , loss = 'exponential' )\n",
        "\n",
        "rf = Pipeline([\n",
        "    ('preprocess', preprocessing),\n",
        "    # ('pca', PCA(n_components = 100)),\n",
        "    ('classifier', model)\n",
        "])\n",
        "\n",
        "rf.fit(X_train[selected_columns], y_train)\n",
        "cv = StratifiedKFold()\n",
        "score = cross_val_score(rf, X_train[selected_columns], y_train, cv=cv)\n",
        "\n",
        "try:\n",
        "  y_pred_rt = rf.predict_proba(X_test[selected_columns])[:, 1]\n",
        "except:\n",
        "  y_pred_rt = rf.predict(X_test[selected_columns])\n",
        "\n",
        "fpr_rt_lm, tpr_rt_lm, _ = roc_curve(y_test, y_pred_rt)\n",
        "auc_s = auc(fpr_rt_lm, tpr_rt_lm)\n",
        "print('AUC: ', auc_s)\n",
        "print('Gini: ', 2*auc_s - 1)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_rt_lm, tpr_rt_lm, label='RT + LR')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgMt-9uMAUV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf['pca'].explained_variance_ratio_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC6TfPN1i0wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train[cols_date].apply(lambda x: ( pd.to_datetime(x.apply(lambda i: str(i)[0:10]) , format=format , errors= 'coerce')  \n",
        "#                               - pd.to_datetime('20170101', format='%Y%m%d')).apply(lambda x: x.days)\n",
        "#                        , axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iODPgpHW9N8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # SVM\n",
        "# categorical_pipe = Pipeline([\n",
        "#     ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "# ])\n",
        "# numerical_pipe = Pipeline([\n",
        "#     ('imputer', SimpleImputer(strategy='mean'))\n",
        "#     , ('standard', StandardScaler()) # Với tree thì không cần standard\n",
        "# ])\n",
        "\n",
        "# preprocessing = ColumnTransformer(\n",
        "#     [('cat', categorical_pipe, cols_categorical),\n",
        "#      ('num', numerical_pipe, cols_fts_num)])\n",
        "\n",
        "# pipeline = Pipeline([\n",
        "#     ('preprocess', preprocessing),\n",
        "#     ('classifier', SVC(probability = True))\n",
        "# ])\n",
        "# pipeline.fit(X_train, y_train)\n",
        "\n",
        "# y_pred_rt = pipeline.predict_proba(X_test)[:, 1]\n",
        "# fpr_rt_lm, tpr_rt_lm, _ = roc_curve(y_test, y_pred_rt)\n",
        "# print('AUC: ', auc(fpr_rt_lm, tpr_rt_lm))\n",
        "\n",
        "# plt.plot([0, 1], [0, 1], 'k--')\n",
        "# plt.plot(fpr_rt_lm, tpr_rt_lm, label='RT + LR')\n",
        "# plt.xlabel('False positive rate')\n",
        "# plt.ylabel('True positive rate')\n",
        "# plt.title('ROC curve')\n",
        "# plt.legend(loc='best')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPs4HgzMCgWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # TF nets\n",
        "# class DenseTransformer(TransformerMixin):\n",
        "\n",
        "#     def fit(self, X, y=None, **fit_params):\n",
        "#         return self\n",
        "\n",
        "#     def transform(self, X, y=None, **fit_params):\n",
        "#         return X.todense()\n",
        "\n",
        "# categorical_pipe = Pipeline([\n",
        "#     ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "#     ('to_string', ToString()),\n",
        "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "# ])\n",
        "# numerical_pipe = Pipeline([\n",
        "#     ('imputer', SimpleImputer(strategy='mean'))\n",
        "#     # , ('standard', StandardScaler()) # Với tree thì không cần standard\n",
        "# ])\n",
        "\n",
        "# preprocessing = ColumnTransformer(\n",
        "#     [('cat', categorical_pipe, cols_categorical),\n",
        "#      ('num', numerical_pipe, cols_fts_num)])\n",
        "\n",
        "# def building_net_func():\n",
        "#   net = Sequential(\n",
        "#       [\n",
        "#       BatchNormalization (),\n",
        "#       Dense(1024, activation ='relu', kernel_initializer = 'he_normal'),\n",
        "#       Dropout(0.5), \n",
        "#       BatchNormalization (),\n",
        "#       Dense(128, activation ='relu', kernel_initializer = 'he_normal'),\n",
        "#       Dropout(0.25), \n",
        "#       # BatchNormalization (),\n",
        "#       # Dense(64, activation ='relu', kernel_initializer = 'he_normal'),\n",
        "#       # Dropout(0.25), \n",
        "#       # BatchNormalization (),\n",
        "#       Dense(16, activation ='relu', kernel_initializer = 'he_normal'),\n",
        "#       BatchNormalization (),\n",
        "#       Dense(1, activation ='sigmoid', kernel_initializer = 'he_normal')])\n",
        "#   net.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = [ AUC() ] )\n",
        "#   return net\n",
        "\n",
        "# net = KerasRegressor(build_fn= building_net_func, verbose = 1)\n",
        "\n",
        "# pipeline = Pipeline([\n",
        "#     ('preprocess', preprocessing),\n",
        "#     ('todense', DenseTransformer()),\n",
        "#     ('classifier', net)\n",
        "# ])\n",
        "# pipeline.fit(\n",
        "#     pd.concat([X_train, X_test])[selected_columns],\n",
        "#     np.concatenate( [y_train, y_test])\n",
        "#     , classifier__epochs = 8\n",
        "#     , classifier__batch_size = 1024\n",
        "#     , classifier__validation_split = 0.2)\n",
        "\n",
        "# y_pred_rt = pipeline.predict(X_test)\n",
        "# fpr_rt_lm, tpr_rt_lm, _ = roc_curve(y_test, y_pred_rt)\n",
        "# print('AUC: ', auc(fpr_rt_lm, tpr_rt_lm))\n",
        "\n",
        "# plt.plot([0, 1], [0, 1], 'k--')\n",
        "# plt.plot(fpr_rt_lm, tpr_rt_lm, label='RT + LR')\n",
        "# plt.xlabel('False positive rate')\n",
        "# plt.ylabel('True positive rate')\n",
        "# plt.title('ROC curve')\n",
        "# plt.legend(loc='best')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvh36b5dIOjE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = pipeline.predict(predict_data[selected_columns])\n",
        "res_df = pd.DataFrame({'id': predict_data.id, 'label': prediction})\n",
        "res_df.to_csv('submission_net.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCi6u6n10qAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ohe = (rf.named_steps['preprocess']\n",
        "#          .named_transformers_['cat']\n",
        "#          .named_steps['onehot'])\n",
        "# feature_names = ohe.get_feature_names(input_features=cols_categorical)\n",
        "# feature_names = np.r_[feature_names, cols_fts_num]\n",
        "\n",
        "# tree_feature_importances = (\n",
        "#     rf.named_steps['classifier'].feature_importances_)\n",
        "# sorted_idx = tree_feature_importances.argsort()\n",
        "\n",
        "# fts_im_num = 15\n",
        "# y_ticks = np.arange(0, fts_im_num)\n",
        "# fig, ax = plt.subplots()\n",
        "# ax.barh(y_ticks, tree_feature_importances[sorted_idx[:fts_im_num]])\n",
        "# ax.set_yticklabels(feature_names[sorted_idx[:fts_im_num]])\n",
        "# ax.set_yticks(y_ticks)\n",
        "# ax.set_title(\"Random Forest Feature Importances (MDI)\")\n",
        "# fig.tight_layout()\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9LsZO6v2aiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sorted_idx[:15]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWrKJNfU9aDO",
        "colab_type": "text"
      },
      "source": [
        "Dự đoán kết quả"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D41J0WI22g05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  prediction = rf.predict_proba(predict_data[selected_columns])[:, 1]\n",
        "except:\n",
        "  prediction = rf.predict(predict_data[selected_columns])\n",
        "res_df = pd.DataFrame({'id': predict_data.id, 'label': prediction})\n",
        "res_df.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRAr9z2Y9qYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}