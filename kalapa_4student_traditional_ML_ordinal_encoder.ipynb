{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kalapa_4student_traditional_ML.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/quanvu0996/compet/blob/master/kalapa_4student_traditional_ML_ordinal_encoder.ipynb",
      "authorship_tag": "ABX9TyMxw1dHITy7dau0ICVyB57q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quanvu0996/compet/blob/master/kalapa_4student_traditional_ML_ordinal_encoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnLk6f0nuwj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, DenseFeatures, Dropout, BatchNormalization, Embedding\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow import feature_column as fc\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set(style=\"ticks\", color_codes=True)\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score,roc_curve, auc\n",
        "from sklearn.utils import check_random_state\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "import xgboost as xgb\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-qcYZ8Fv1TH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b0f1457d-b7b6-462b-fefe-8ea5af393427"
      },
      "source": [
        "print(pd.__version__)\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0.5\n",
            "2.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j7u_eUMv9Zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submision_path = '/content/drive/My Drive/Data/colabs_data/kalapa_4students/simple_submission.csv'\n",
        "train_path = '/content/drive/My Drive/Data/colabs_data/kalapa_4students/train.csv'\n",
        "test_path = '/content/drive/My Drive/Data/colabs_data/kalapa_4students/test.csv'\n",
        "\n",
        "added_data_path= '/content/drive/My Drive/Data/colabs_data/kalapa_4students/exdata.txt'"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqoJojArwAM6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "0533bf37-7019-405f-a158-9714f7e500e3"
      },
      "source": [
        "def load_data(train_path, test_path, label_col = 'label'):\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    predict_data = pd.read_csv(test_path)\n",
        "    return train_data, predict_data\n",
        "\n",
        "train_data, predict_data = load_data( train_path, test_path )\n",
        "train_data = train_data[train_data['label'].isin( [0,1] )].replace('notfound','missing')\n",
        "predict_data = predict_data.replace('notfound','missing')\n",
        "cols = train_data.columns"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (35,43) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n",
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2822: DtypeWarning: Columns (34,42) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  if self.run_code(code, result):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbBLkOqGN7F4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "dd75cd57-e593-47ad-c047-51d707cd6b48"
      },
      "source": [
        "# train_data.merge()\n",
        "added_data = pd.read_csv(added_data_path, sep='\\t', encoding='utf-8')\n",
        "added_data"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>province</th>\n",
              "      <th>area</th>\n",
              "      <th>population</th>\n",
              "      <th>pop_density</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hà Nội</td>\n",
              "      <td>3358.6</td>\n",
              "      <td>8093.9</td>\n",
              "      <td>2410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Vĩnh Phúc</td>\n",
              "      <td>1235.9</td>\n",
              "      <td>1154.8</td>\n",
              "      <td>934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bắc Ninh</td>\n",
              "      <td>822.7</td>\n",
              "      <td>1378.6</td>\n",
              "      <td>1676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Quảng Ninh</td>\n",
              "      <td>6178.2</td>\n",
              "      <td>1324.8</td>\n",
              "      <td>214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hải Dương</td>\n",
              "      <td>1668.2</td>\n",
              "      <td>1896.9</td>\n",
              "      <td>1137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>Cần Thơ</td>\n",
              "      <td>1439.0</td>\n",
              "      <td>1236.0</td>\n",
              "      <td>859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>Hậu Giang</td>\n",
              "      <td>1621.7</td>\n",
              "      <td>732.2</td>\n",
              "      <td>451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>Sóc Trăng</td>\n",
              "      <td>3311.9</td>\n",
              "      <td>1199.5</td>\n",
              "      <td>362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>Bạc Liêu</td>\n",
              "      <td>2669.0</td>\n",
              "      <td>908.2</td>\n",
              "      <td>340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>Cà Mau</td>\n",
              "      <td>5221.2</td>\n",
              "      <td>1194.3</td>\n",
              "      <td>229</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>64 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      province    area  population  pop_density\n",
              "0       Hà Nội  3358.6      8093.9         2410\n",
              "1    Vĩnh Phúc  1235.9      1154.8          934\n",
              "2     Bắc Ninh   822.7      1378.6         1676\n",
              "3   Quảng Ninh  6178.2      1324.8          214\n",
              "4    Hải Dương  1668.2      1896.9         1137\n",
              "..         ...     ...         ...          ...\n",
              "59     Cần Thơ  1439.0      1236.0          859\n",
              "60   Hậu Giang  1621.7       732.2          451\n",
              "61   Sóc Trăng  3311.9      1199.5          362\n",
              "62    Bạc Liêu  2669.0       908.2          340\n",
              "63      Cà Mau  5221.2      1194.3          229\n",
              "\n",
              "[64 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oprz_imExUEA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "b3bcb609-1ceb-4672-b28c-2e2483a8b002"
      },
      "source": [
        "train_data['homeTownName'].unique()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([nan, 'Hà Nội', 'Qui Nhon, Bình Ðịnh, Vietnam', ...,\n",
              "       'Kim Mã, Ha Noi, Vietnam', 'Busan', 'An Lão, Bình Ðịnh, Vietnam'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrXATFIdwCZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Nhãn\n",
        "cols_label = ['label']\n",
        "# Đặc trưng binary\n",
        "cols_fts_binary = [i for i in train_data.select_dtypes(include=['float64','int64']).columns \n",
        "                   if len(set(train_data[i].fillna(0)) - {0,1} ) == 0 and i not in cols_label]\n",
        "# định dang datte yyyy-mm-dd\n",
        "cols_date = ['Field_1','Field_2','Field_5','Field_6','Field_7','Field_8','Field_9','Field_11'\n",
        "             ,'Field_15','Field_25','Field_32','Field_33','Field_35','Field_40','Field_43','Field_44'\n",
        "             ,'F_startDate','F_endDate','E_startDate','E_endDate','C_startDate','C_endDate','G_startDate','G_endDate'\n",
        "             ,'A_startDate','A_endDate']\n",
        "# định dạng date yyymmdd\n",
        "cols_date2 = ['ngaySinh', 'Field_34']\n",
        "# Đặc trưng dạng văn bản\n",
        "cols_docs = ['Field_46','diaChi','Field_48','Field_49','currentLocationName','homeTownName','Field_56']\n",
        "# Định danh bản ghi\n",
        "cols_id = ['id','Field_45'] +[i for i in train_data.select_dtypes(include = ['object']).columns \n",
        "                              if len(train_data[i].unique()) >=350 and i not in cols_date + cols_date2+cols_docs]\n",
        "# Đặc trưng dạng categorical\n",
        "cols_categorical = [i for i in train_data.select_dtypes(include = ['object']).columns\n",
        "                    if i not in cols_id + cols_label+cols_date2+cols_date+cols_docs]\n",
        "# Đặc trưng số\n",
        "cols_fts_num = [ i for i in predict_data.select_dtypes(include=['float64','int64']).columns \n",
        "                if i not in cols_id + cols_label + cols_fts_binary + cols_date2+cols_date+cols_docs]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD5nD91PwGlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Đặc trưng số có dạng như categorical\n",
        "cols_num_like_cat = [i for i in cols_fts_num if len(train_data[i].unique()) <= 15 ]\n",
        "# Đặc trưng số đã kiểm chứng\n",
        "cols_num = [i for i in cols_fts_num if i not in cols_num_like_cat]\n",
        "\n",
        "cols_categorical = list(set(cols_categorical + cols_num_like_cat))\n",
        "cols_fts_num = [i for i in cols_fts_num if i not in cols_num_like_cat ]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VKHHN7nwqvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(train_data\n",
        "                                                   ,train_data['label'].values\n",
        "                                                   ,stratify = train_data['label'].values \n",
        "                                                   ,test_size = 0.2\n",
        "                                                   )"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QaLF849KxaJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4871d6a-1157-4684-9c4d-498637ad8fee"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(42424, 195)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM5JDQMY5_l6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# OneHotEncoder(handle_unknown='ignore').fit(X_train[cols_categorical].astype(str).fillna('ms'))\n",
        "# X_train[cols_categorical].astype(str).info()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTqBRiQpbgvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train[cols_date].head().apply(lambda x: ( pd.to_datetime(x.apply(lambda i: str(i)[0:10]) , format='%Y-%m-%d' , errors= 'coerce')  \n",
        "#                                           - pd.to_datetime('20170101', format='%Y%m%d')).apply(lambda x: x.days)\n",
        "#                               , axis = 1)\n",
        "# X_train[cols_date].head().apply(lambda x: ( pd.to_datetime(x.apply(lambda i: str(i)[0:10]) , format=format , errors= 'coerce')  \n",
        "#                               - pd.to_datetime('20170101', format='%Y%m%d')).apply(lambda x: x.days)\n",
        "#                        , axis = 1)\n",
        "\n",
        "# (pd.to_datetime( df[col].apply(lambda x: str(x)[0:10]), format='%Y-%m-%d' , errors= 'coerce') \n",
        "#                         - pd.to_datetime('20170101', format='%Y%m%d') ).apply(lambda x: x.days)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-pFSxh8C1FQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lấy list value cho ordinalencoder\n",
        "categories_val = []\n",
        "for i in cols_categorical:\n",
        "  categories_val.append(list( \n",
        "      pd.concat([train_data[i], predict_data[i]]).fillna('missing').apply(lambda x: str(x)).drop_duplicates( \n",
        "  ).sort_values().values) )"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTPdZjYZwuzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Xây dựng pipeline và fit với tree-based\n",
        "selected_columns = cols_categorical+cols_fts_num + cols_date + cols_date2\n",
        "\n",
        "class ToString(BaseEstimator, TransformerMixin):\n",
        "  '''Def 1 trans để convert các cột dạng số như categorical thành dạng cat => dùng được onehot'''\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "  def transform(self, X, y = None):\n",
        "    X_ = X.copy() # creating a copy to avoid changes to original dataset\n",
        "    X_ = X_.astype(str)\n",
        "    return X_\n",
        "\n",
        "class DateToNum(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, format = '%Y-%m-%d' ):\n",
        "    self.format = format\n",
        "  def fit(self, X, y = None):\n",
        "    return self\n",
        "  def transform(self, X, y = None):\n",
        "    X_ = X.copy() # creating a copy to avoid changes to original dataset\n",
        "    X_ = X_.apply(lambda x: ( pd.to_datetime(x.apply(lambda i: str(i)[0:10]) , format= self.format , errors= 'coerce')  \n",
        "                              - pd.to_datetime('20170101', format='%Y%m%d')).apply(lambda x: x.days)\n",
        "                       , axis = 1)\n",
        "    for i in X_.columns:\n",
        "      X_[i+'year_as_number'] = pd.to_datetime(X_[i].apply(lambda i: str(i)[0:10])\n",
        "                                        , format= self.format , errors= 'coerce').dt.year -2010\n",
        "      X_[i+'month_as_number'] = pd.to_datetime(X_[i].apply(lambda i: str(i)[0:10])\n",
        "                                        , format= self.format , errors= 'coerce').dt.month\n",
        "      X_[i+'day_as_number'] = pd.to_datetime(X_[i].apply(lambda i: str(i)[0:10])\n",
        "                                        , format= self.format , errors= 'coerce').dt.day\n",
        "    return X_\n",
        "\n",
        "categorical_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing'))\n",
        "    , ('to_string', ToString())\n",
        "    , ('onehot', OrdinalEncoder(categories=categories_val))\n",
        "])\n",
        "numerical_pipe = Pipeline([\n",
        "    ('imputer', SimpleImputer(strategy='mean'))\n",
        "    # , ('standard', StandardScaler()) # Với tree thì không cần standard\n",
        "])\n",
        "\n",
        "datetime_pipe1 = Pipeline([\n",
        "    ('datetime1', DateToNum(format='%Y-%m-%d'))\n",
        "    # , ('standard', StandardScaler()) # Với tree thì không cần standard\n",
        "    , ('imputer', SimpleImputer(strategy='mean'))\n",
        "])\n",
        "\n",
        "datetime_pipe2 = Pipeline([\n",
        "    ('datetime2', DateToNum(format='%Y%m%d'))\n",
        "    # , ('standard', StandardScaler()) # Với tree thì không cần standard\n",
        "    , ('imputer', SimpleImputer(strategy='mean'))\n",
        "])\n",
        "\n",
        "preprocessing = ColumnTransformer(\n",
        "    [\n",
        "     ('cat', categorical_pipe, cols_categorical),\n",
        "     ('num', numerical_pipe, cols_fts_num), \n",
        "     ('date1', datetime_pipe1, cols_date),\n",
        "     ('date2', datetime_pipe2, cols_date2)\n",
        "     ])\n",
        "\n",
        "#xgb.XGBRegressor(objective=\"reg:linear\", random_state=42, n_estimators =64, max_depth =7)\n",
        "model =  LGBMClassifier(\n",
        "            nthread=4,\n",
        "            n_estimators=10000,\n",
        "            learning_rate=0.02,\n",
        "            num_leaves=128,\n",
        "            colsample_bytree=0.9497036,\n",
        "            subsample=0.8715623,\n",
        "            max_depth=8,\n",
        "            reg_alpha=0.041545473,\n",
        "            reg_lambda=0.0735294,\n",
        "            min_split_gain=0.0222415,\n",
        "            min_child_weight=39.3259775,\n",
        "            silent=-1,\n",
        "            verbose=-1\n",
        "        )\n",
        "# GradientBoostingClassifier(random_state=42, \n",
        "#                                               max_depth = 7\n",
        "#                                               # , loss = 'exponential' \n",
        "#                                               )\n",
        "\n",
        "rf = Pipeline([\n",
        "    ('preprocess', preprocessing),\n",
        "    # ('pca', PCA(n_components = 100)),\n",
        "    ('classifier', model)\n",
        "])\n",
        "\n",
        "# rf.fit(X_train[selected_columns], y_train)\n",
        "cv = StratifiedKFold()\n",
        "score = cross_val_score(rf, X_train[selected_columns], y_train, cv=cv)\n",
        "\n",
        "try:\n",
        "  y_pred_rt = rf.predict_proba(X_test[selected_columns])[:, 1]\n",
        "except:\n",
        "  y_pred_rt = rf.predict(X_test[selected_columns])\n",
        "\n",
        "fpr_rt_lm, tpr_rt_lm, _ = roc_curve(y_test, y_pred_rt)\n",
        "auc_s = auc(fpr_rt_lm, tpr_rt_lm)\n",
        "print('AUC: ', auc_s)\n",
        "print('Gini': 2*auc_s - 1)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "plt.plot(fpr_rt_lm, tpr_rt_lm, label='RT + LR')\n",
        "plt.xlabel('False positive rate')\n",
        "plt.ylabel('True positive rate')\n",
        "plt.title('ROC curve')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgMt-9uMAUV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf['pca'].explained_variance_ratio_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC6TfPN1i0wo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# X_train[cols_date].apply(lambda x: ( pd.to_datetime(x.apply(lambda i: str(i)[0:10]) , format=format , errors= 'coerce')  \n",
        "#                               - pd.to_datetime('20170101', format='%Y%m%d')).apply(lambda x: x.days)\n",
        "#                        , axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iODPgpHW9N8R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # SVM\n",
        "# categorical_pipe = Pipeline([\n",
        "#     ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "# ])\n",
        "# numerical_pipe = Pipeline([\n",
        "#     ('imputer', SimpleImputer(strategy='mean'))\n",
        "#     , ('standard', StandardScaler()) # Với tree thì không cần standard\n",
        "# ])\n",
        "\n",
        "# preprocessing = ColumnTransformer(\n",
        "#     [('cat', categorical_pipe, cols_categorical),\n",
        "#      ('num', numerical_pipe, cols_fts_num)])\n",
        "\n",
        "# pipeline = Pipeline([\n",
        "#     ('preprocess', preprocessing),\n",
        "#     ('classifier', SVC(probability = True))\n",
        "# ])\n",
        "# pipeline.fit(X_train, y_train)\n",
        "\n",
        "# y_pred_rt = pipeline.predict_proba(X_test)[:, 1]\n",
        "# fpr_rt_lm, tpr_rt_lm, _ = roc_curve(y_test, y_pred_rt)\n",
        "# print('AUC: ', auc(fpr_rt_lm, tpr_rt_lm))\n",
        "\n",
        "# plt.plot([0, 1], [0, 1], 'k--')\n",
        "# plt.plot(fpr_rt_lm, tpr_rt_lm, label='RT + LR')\n",
        "# plt.xlabel('False positive rate')\n",
        "# plt.ylabel('True positive rate')\n",
        "# plt.title('ROC curve')\n",
        "# plt.legend(loc='best')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPs4HgzMCgWp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # TF nets\n",
        "# class DenseTransformer(TransformerMixin):\n",
        "\n",
        "#     def fit(self, X, y=None, **fit_params):\n",
        "#         return self\n",
        "\n",
        "#     def transform(self, X, y=None, **fit_params):\n",
        "#         return X.todense()\n",
        "\n",
        "# categorical_pipe = Pipeline([\n",
        "#     ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "#     ('to_string', ToString()),\n",
        "#     ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "# ])\n",
        "# numerical_pipe = Pipeline([\n",
        "#     ('imputer', SimpleImputer(strategy='mean'))\n",
        "#     # , ('standard', StandardScaler()) # Với tree thì không cần standard\n",
        "# ])\n",
        "\n",
        "# preprocessing = ColumnTransformer(\n",
        "#     [('cat', categorical_pipe, cols_categorical),\n",
        "#      ('num', numerical_pipe, cols_fts_num)])\n",
        "\n",
        "# def building_net_func():\n",
        "#   net = Sequential(\n",
        "#       [\n",
        "#       BatchNormalization (),\n",
        "#       Dense(1024, activation ='relu', kernel_initializer = 'he_normal'),\n",
        "#       Dropout(0.5), \n",
        "#       BatchNormalization (),\n",
        "#       Dense(128, activation ='relu', kernel_initializer = 'he_normal'),\n",
        "#       Dropout(0.25), \n",
        "#       # BatchNormalization (),\n",
        "#       # Dense(64, activation ='relu', kernel_initializer = 'he_normal'),\n",
        "#       # Dropout(0.25), \n",
        "#       # BatchNormalization (),\n",
        "#       Dense(16, activation ='relu', kernel_initializer = 'he_normal'),\n",
        "#       BatchNormalization (),\n",
        "#       Dense(1, activation ='sigmoid', kernel_initializer = 'he_normal')])\n",
        "#   net.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = [ AUC() ] )\n",
        "#   return net\n",
        "\n",
        "# net = KerasRegressor(build_fn= building_net_func, verbose = 1)\n",
        "\n",
        "# pipeline = Pipeline([\n",
        "#     ('preprocess', preprocessing),\n",
        "#     ('todense', DenseTransformer()),\n",
        "#     ('classifier', net)\n",
        "# ])\n",
        "# pipeline.fit(\n",
        "#     pd.concat([X_train, X_test])[selected_columns],\n",
        "#     np.concatenate( [y_train, y_test])\n",
        "#     , classifier__epochs = 8\n",
        "#     , classifier__batch_size = 1024\n",
        "#     , classifier__validation_split = 0.2)\n",
        "\n",
        "# y_pred_rt = pipeline.predict(X_test)\n",
        "# fpr_rt_lm, tpr_rt_lm, _ = roc_curve(y_test, y_pred_rt)\n",
        "# print('AUC: ', auc(fpr_rt_lm, tpr_rt_lm))\n",
        "\n",
        "# plt.plot([0, 1], [0, 1], 'k--')\n",
        "# plt.plot(fpr_rt_lm, tpr_rt_lm, label='RT + LR')\n",
        "# plt.xlabel('False positive rate')\n",
        "# plt.ylabel('True positive rate')\n",
        "# plt.title('ROC curve')\n",
        "# plt.legend(loc='best')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvh36b5dIOjE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "d0bac56c-1207-4a42-ebd0-4372b2551b2d"
      },
      "source": [
        "prediction = pipeline.predict(predict_data[selected_columns])\n",
        "res_df = pd.DataFrame({'id': predict_data.id, 'label': prediction})\n",
        "res_df.to_csv('submission_net.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-75ebd9808b83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_columns\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mres_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredict_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mres_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'submission_net.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCi6u6n10qAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ohe = (rf.named_steps['preprocess']\n",
        "#          .named_transformers_['cat']\n",
        "#          .named_steps['onehot'])\n",
        "# feature_names = ohe.get_feature_names(input_features=cols_categorical)\n",
        "# feature_names = np.r_[feature_names, cols_fts_num]\n",
        "\n",
        "# tree_feature_importances = (\n",
        "#     rf.named_steps['classifier'].feature_importances_)\n",
        "# sorted_idx = tree_feature_importances.argsort()\n",
        "\n",
        "# fts_im_num = 15\n",
        "# y_ticks = np.arange(0, fts_im_num)\n",
        "# fig, ax = plt.subplots()\n",
        "# ax.barh(y_ticks, tree_feature_importances[sorted_idx[:fts_im_num]])\n",
        "# ax.set_yticklabels(feature_names[sorted_idx[:fts_im_num]])\n",
        "# ax.set_yticks(y_ticks)\n",
        "# ax.set_title(\"Random Forest Feature Importances (MDI)\")\n",
        "# fig.tight_layout()\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9LsZO6v2aiw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sorted_idx[:15]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWrKJNfU9aDO",
        "colab_type": "text"
      },
      "source": [
        "Dự đoán kết quả"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D41J0WI22g05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  prediction = rf.predict_proba(predict_data[selected_columns])[:, 1]\n",
        "except:\n",
        "  prediction = rf.predict(predict_data[selected_columns])\n",
        "res_df = pd.DataFrame({'id': predict_data.id, 'label': prediction})\n",
        "res_df.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRAr9z2Y9qYa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5f3de056-f8ac-4b19-e98e-e5025385554b"
      },
      "source": [
        "predict_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.24803742, 0.31890366, 0.4028687 , ..., 0.10729143, 0.26460362,\n",
              "       0.19883522])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    }
  ]
}