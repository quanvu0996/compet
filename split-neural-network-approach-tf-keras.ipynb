{
 "cells": [
  {
   "attachments": {
    "SplitNN.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Neural Network\n",
    "\n",
    "[Split Neural Network (SplitNN)][1] is a kind of distributed learning approach. It uses multiple splits of NN to train with different portions of features and then aggregated by another NN. It is very similar to the stacking ensemble of multiple NNs. Let's see if this approach works.\n",
    "\n",
    "![SplitNN.png](attachment:SplitNN.png)\n",
    "\n",
    "[1]:https://arxiv.org/pdf/1812.00564.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.2.0\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# import sys\n",
    "# sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "import gc\n",
    "import datetime\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.models as M\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "import tensorflow_addons as tfa\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from scipy.optimize import minimize\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time\n",
    "\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerated Linear Algebra enabled\n"
     ]
    }
   ],
   "source": [
    "MIXED_PRECISION = False\n",
    "XLA_ACCELERATE = True\n",
    "\n",
    "if MIXED_PRECISION:\n",
    "    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "    if tpu: policy = tf.keras.mixed_precision.experimental.Policy('mixed_bfloat16')\n",
    "    else: policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "    mixed_precision.set_policy(policy)\n",
    "    print('Mixed precision enabled')\n",
    "\n",
    "if XLA_ACCELERATE:\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "    print('Accelerated Linear Algebra enabled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('train_features.csv')\n",
    "train_targets = pd.read_csv('train_targets_scored.csv')\n",
    "test_features = pd.read_csv('test_features.csv')\n",
    "\n",
    "ss = pd.read_csv('sample_submission.csv')\n",
    "ss_2 = ss.copy()\n",
    "ss_3 = ss.copy()\n",
    "ss_blend = ss.copy()\n",
    "\n",
    "cols = [c for c in ss.columns.values if c != 'sig_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df.loc[:, 'cp_type'] = df.loc[:, 'cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    df.loc[:, 'cp_dose'] = df.loc[:, 'cp_dose'].map({'D1': 0, 'D2': 1})\n",
    "    del df['sig_id']\n",
    "    return df\n",
    "\n",
    "def log_loss_metric(y_true, y_pred):\n",
    "    metrics = []\n",
    "    for _target in train_targets.columns:\n",
    "        metrics.append(log_loss(y_true.loc[:, _target], y_pred.loc[:, _target].astype(float), labels = [0,1]))\n",
    "    return np.mean(metrics)\n",
    "\n",
    "train = preprocess(train_features)\n",
    "test = preprocess(test_features)\n",
    "\n",
    "del train_targets['sig_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696\n"
     ]
    }
   ],
   "source": [
    "top_feats = [  0,   1,   2,   3,   5,   6,   8,   9,  10,  11,  12,  14,  15,\n",
    "        16,  18,  19,  20,  21,  23,  24,  25,  27,  28,  29,  30,  31,\n",
    "        32,  33,  34,  35,  36,  37,  39,  40,  41,  42,  44,  45,  46,\n",
    "        48,  50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,\n",
    "        63,  64,  65,  66,  68,  69,  70,  71,  72,  73,  74,  75,  76,\n",
    "        78,  79,  80,  81,  82,  83,  84,  86,  87,  88,  89,  90,  92,\n",
    "        93,  94,  95,  96,  97,  99, 100, 101, 103, 104, 105, 106, 107,\n",
    "       108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120,\n",
    "       121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 134,\n",
    "       135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147,\n",
    "       149, 150, 151, 152, 153, 154, 155, 157, 159, 160, 161, 163, 164,\n",
    "       165, 166, 167, 168, 169, 170, 172, 173, 175, 176, 177, 178, 180,\n",
    "       181, 182, 183, 184, 186, 187, 188, 189, 190, 191, 192, 193, 195,\n",
    "       197, 198, 199, 202, 203, 205, 206, 208, 209, 210, 211, 212, 213,\n",
    "       214, 215, 218, 219, 220, 221, 222, 224, 225, 227, 228, 229, 230,\n",
    "       231, 232, 233, 234, 236, 238, 239, 240, 241, 242, 243, 244, 245,\n",
    "       246, 248, 249, 250, 251, 253, 254, 255, 256, 257, 258, 259, 260,\n",
    "       261, 263, 265, 266, 268, 270, 271, 272, 273, 275, 276, 277, 279,\n",
    "       282, 283, 286, 287, 288, 289, 290, 294, 295, 296, 297, 299, 300,\n",
    "       301, 302, 303, 304, 305, 306, 308, 309, 310, 311, 312, 313, 315,\n",
    "       316, 317, 320, 321, 322, 324, 325, 326, 327, 328, 329, 330, 331,\n",
    "       332, 333, 334, 335, 338, 339, 340, 341, 343, 344, 345, 346, 347,\n",
    "       349, 350, 351, 352, 353, 355, 356, 357, 358, 359, 360, 361, 362,\n",
    "       363, 364, 365, 366, 368, 369, 370, 371, 372, 374, 375, 376, 377,\n",
    "       378, 379, 380, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
    "       392, 393, 394, 395, 397, 398, 399, 400, 401, 403, 405, 406, 407,\n",
    "       408, 410, 411, 412, 413, 414, 415, 417, 418, 419, 420, 421, 422,\n",
    "       423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435,\n",
    "       436, 437, 438, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450,\n",
    "       452, 453, 454, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465,\n",
    "       466, 468, 469, 471, 472, 473, 474, 475, 476, 477, 478, 479, 482,\n",
    "       483, 485, 486, 487, 488, 489, 491, 492, 494, 495, 496, 500, 501,\n",
    "       502, 503, 505, 506, 507, 509, 510, 511, 512, 513, 514, 516, 517,\n",
    "       518, 519, 521, 523, 525, 526, 527, 528, 529, 530, 531, 532, 533,\n",
    "       534, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547,\n",
    "       549, 550, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563,\n",
    "       564, 565, 566, 567, 569, 570, 571, 572, 573, 574, 575, 577, 580,\n",
    "       581, 582, 583, 586, 587, 590, 591, 592, 593, 595, 596, 597, 598,\n",
    "       599, 600, 601, 602, 603, 605, 607, 608, 609, 611, 612, 613, 614,\n",
    "       615, 616, 617, 619, 622, 623, 625, 627, 630, 631, 632, 633, 634,\n",
    "       635, 637, 638, 639, 642, 643, 644, 645, 646, 647, 649, 650, 651,\n",
    "       652, 654, 655, 658, 659, 660, 661, 662, 663, 664, 666, 667, 668,\n",
    "       669, 670, 672, 674, 675, 676, 677, 678, 680, 681, 682, 684, 685,\n",
    "       686, 687, 688, 689, 691, 692, 694, 695, 696, 697, 699, 700, 701,\n",
    "       702, 703, 704, 705, 707, 708, 709, 711, 712, 713, 714, 715, 716,\n",
    "       717, 723, 725, 727, 728, 729, 730, 731, 732, 734, 736, 737, 738,\n",
    "       739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751,\n",
    "       752, 753, 754, 755, 756, 758, 759, 760, 761, 762, 763, 764, 765,\n",
    "       766, 767, 769, 770, 771, 772, 774, 775, 780, 781, 782, 783, 784,\n",
    "       785, 787, 788, 790, 793, 795, 797, 799, 800, 801, 805, 808, 809,\n",
    "       811, 812, 813, 816, 819, 820, 821, 822, 823, 825, 826, 827, 829,\n",
    "       831, 832, 833, 834, 835, 837, 838, 839, 840, 841, 842, 844, 845,\n",
    "       846, 847, 848, 850, 851, 852, 854, 855, 856, 858, 860, 861, 862,\n",
    "       864, 867, 868, 870, 871, 873, 874]\n",
    "\n",
    "print(len(top_feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(num_columns, hidden_units, dropout_rate, learning_rate):\n",
    "        \n",
    "    inp1 = tf.keras.layers.Input(shape = (num_columns, ))\n",
    "    x1 = tf.keras.layers.BatchNormalization()(inp1)\n",
    "    \n",
    "    for i, units in enumerate(hidden_units[0]):\n",
    "        x1 = tfa.layers.WeightNormalization(tf.keras.layers.Dense(units, activation = 'elu'))(x1)\n",
    "        x1 = tf.keras.layers.Dropout(dropout_rate[0])(x1)\n",
    "        x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "        \n",
    "    inp2 = tf.keras.layers.Input(shape = (num_columns, ))\n",
    "    x2 = tf.keras.layers.BatchNormalization()(inp2)\n",
    "    \n",
    "    for i, units in enumerate(hidden_units[1]):\n",
    "        x2 = tfa.layers.WeightNormalization(tf.keras.layers.Dense(units, activation = 'elu'))(x2)\n",
    "        x2 = tf.keras.layers.Dropout(dropout_rate[1])(x2)\n",
    "        x2 = tf.keras.layers.BatchNormalization()(x2)\n",
    "        \n",
    "    inp3 = tf.keras.layers.Input(shape = (num_columns, ))\n",
    "    x3 = tf.keras.layers.BatchNormalization()(inp3)\n",
    "    \n",
    "    for i, units in enumerate(hidden_units[2]):\n",
    "        x3 = tfa.layers.WeightNormalization(tf.keras.layers.Dense(units, activation = 'elu'))(x3)\n",
    "        x3 = tf.keras.layers.Dropout(dropout_rate[2])(x3)\n",
    "        x3 = tf.keras.layers.BatchNormalization()(x3)\n",
    "        \n",
    "    x = tf.keras.layers.Concatenate()([x1, x2, x3])\n",
    "    x = tf.keras.layers.Dropout(dropout_rate[3])(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    for units in hidden_units[3]:\n",
    "        \n",
    "        x = tfa.layers.WeightNormalization(tf.keras.layers.Dense(units, activation = 'elu'))(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rate[4])(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "    out = tfa.layers.WeightNormalization(tf.keras.layers.Dense(206, activation = 'sigmoid'))(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs = [inp1, inp2, inp3], outputs = out)\n",
    "    \n",
    "    model.compile(optimizer = tfa.optimizers.Lookahead(tf.optimizers.Adam(learning_rate), sync_period = 10), \n",
    "                  loss = 'binary_crossentropy')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            [(None, 700)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 700)          2800        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_20 (Weight (None, 512)          718337      batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 512)          0           weight_normalization_20[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 512)          2048        dropout_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_21 (Weight (None, 1024)         1051649     batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 700)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_5 (InputLayer)            [(None, 700)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 1024)         0           weight_normalization_21[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 700)          2800        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 700)          2800        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 1024)         4096        dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_14 (Weight (None, 2048)         2873345     batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_17 (Weight (None, 512)          718337      batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_22 (Weight (None, 2048)         4200449     batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 2048)         0           weight_normalization_14[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 512)          0           weight_normalization_17[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 2048)         0           weight_normalization_22[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 2048)         8192        dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 512)          2048        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 2048)         8192        dropout_22[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_15 (Weight (None, 512)          2098689     batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_18 (Weight (None, 1024)         1051649     batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_23 (Weight (None, 1024)         4197377     batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 512)          0           weight_normalization_15[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 1024)         0           weight_normalization_18[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 1024)         0           weight_normalization_23[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 512)          2048        dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 1024)         4096        dropout_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 1024)         4096        dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_16 (Weight (None, 2048)         2103297     batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_19 (Weight (None, 512)          1050113     batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_24 (Weight (None, 512)          1050113     batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 2048)         0           weight_normalization_16[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 512)          0           weight_normalization_19[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 512)          0           weight_normalization_24[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 2048)         8192        dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 512)          2048        dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 512)          2048        dropout_24[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3072)         0           batch_normalization_20[0][0]     \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 3072)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 3072)         12288       dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_25 (Weight (None, 1024)         6294529     batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 1024)         0           weight_normalization_25[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 1024)         4096        dropout_26[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_26 (Weight (None, 1024)         2100225     batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 1024)         0           weight_normalization_26[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 1024)         4096        dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "weight_normalization_27 (Weight (None, 206)          422507      batch_normalization_33[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 30,006,600\n",
      "Trainable params: 15,010,308\n",
      "Non-trainable params: 14,996,292\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hidden_units = [[2048, 512, 2048], \n",
    "                [512, 1024, 512], \n",
    "                [512, 1024, 2048, 1024, 512], \n",
    "                [1024, 1024]]\n",
    "\n",
    "dropout_rate = [0.4, 0.3, 0.45, 0.3, 0.4]\n",
    "\n",
    "size = int(np.ceil(0.8 * len(train.columns.values)))\n",
    "\n",
    "model = create_model(size, hidden_units, dropout_rate, 1e-3)\n",
    "# tf.keras.utils.plot_model(model, show_shapes = False, show_layer_names= True,\n",
    "#                           rankdir = 'TB', expand_nested = False, dpi = 96)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "\n",
    "For each split, we use 80\\% of top features as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\quanvh8\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "[43:50] Split NN: Seed 0, Fold 0: 0.015413488261401653\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-501d77ceb60b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m                            baseline = None, restore_best_weights = True, verbose = 0)\n\u001b[0;32m     38\u001b[0m         history = model.fit(x_tr, y_tr, validation_data = (x_val, y_val), \n\u001b[1;32m---> 39\u001b[1;33m                             epochs = 100, batch_size = 128, callbacks = [rlr, ckp, es], verbose = 0)\n\u001b[0m\u001b[0;32m     40\u001b[0m         \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'split_nn.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    609\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    612\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_units = [[2048, 512, 2048], \n",
    "                [512, 1024, 512], \n",
    "                [512, 1024, 2048, 1024, 512], \n",
    "                [1024, 1024]]\n",
    "\n",
    "dropout_rate = [0.4, 0.3, 0.45, 0.3, 0.4]\n",
    "\n",
    "size = int(np.ceil(0.8 * len(top_feats)))\n",
    "\n",
    "res = train_targets.copy()\n",
    "ss.loc[:, train_targets.columns] = 0\n",
    "res.loc[:, train_targets.columns] = 0\n",
    "\n",
    "N_STARTS = 3\n",
    "\n",
    "for seed in range(N_STARTS):\n",
    "    \n",
    "    split_cols = []\n",
    "    for _ in range(len(hidden_units) - 1):\n",
    "        split_cols.append(np.random.choice(top_feats, size))\n",
    "        \n",
    "    for n, (tr, te) in enumerate(MultilabelStratifiedKFold(n_splits = 5, \n",
    "                                                           random_state = seed, \n",
    "                                                           shuffle = True).split(train_targets, train_targets)):\n",
    "        \n",
    "        start_time = time()\n",
    "        \n",
    "        x_tr = [train.values[tr][:, split_cols[0]], train.values[tr][:, split_cols[1]], train.values[tr][:, split_cols[2]]]\n",
    "        x_val = [train.values[te][:, split_cols[0]], train.values[te][:, split_cols[1]], train.values[te][:, split_cols[2]]]\n",
    "        y_tr, y_val = train_targets.astype(float).values[tr], train_targets.astype(float).values[te]\n",
    "        x_tt = [test_features.values[:, split_cols[0]], test_features.values[:, split_cols[1]], test_features.values[:, split_cols[2]]]\n",
    "        \n",
    "        model = create_model(size, hidden_units, dropout_rate, 1e-3)\n",
    "        rlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 3, verbose = 0, \n",
    "                                min_delta = 1e-4, min_lr = 1e-5, mode = 'min')\n",
    "        ckp = ModelCheckpoint(f'split_nn.hdf5', monitor = 'val_loss', verbose = 0, \n",
    "                              save_best_only = True, save_weights_only = True, mode = 'min')\n",
    "        es = EarlyStopping(monitor = 'val_loss', min_delta = 1e-4, patience = 10, mode = 'min', \n",
    "                           baseline = None, restore_best_weights = True, verbose = 0)\n",
    "        history = model.fit(x_tr, y_tr, validation_data = (x_val, y_val), \n",
    "                            epochs = 100, batch_size = 128, callbacks = [rlr, ckp, es], verbose = 0)\n",
    "        hist = pd.DataFrame(history.history)\n",
    "        model.load_weights(f'split_nn.hdf5')\n",
    "        ss.loc[:, train_targets.columns] += model.predict(x_tt, batch_size = 128)\n",
    "        res.loc[te, train_targets.columns] += model.predict(x_val, batch_size = 128)\n",
    "        print(f'[{str(datetime.timedelta(seconds = time() - start_time))[2:7]}] Split NN: Seed {seed}, Fold {n}:', hist['val_loss'].min())\n",
    "        \n",
    "        K.clear_session()\n",
    "        del model, history, hist\n",
    "        x = gc.collect()\n",
    "        \n",
    "ss.loc[:, train_targets.columns] /= ((n + 1) * N_STARTS)\n",
    "res.loc[:, train_targets.columns] /= N_STARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Split NN OOF Metric: {log_loss_metric(train_targets, res)}')\n",
    "res.loc[train['cp_type'] == 1, train_targets.columns] = 0\n",
    "ss.loc[test['cp_type'] == 1, train_targets.columns] = 0\n",
    "print(f'Split NN OOF Metric with postprocessing: {log_loss_metric(train_targets, res)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
